<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>0 on Jun Kang&#39;s Blog</title>
    <link>http://localhost:1313/tags/0/</link>
    <description>Recent content in 0 on Jun Kang&#39;s Blog</description>
    <generator>Hugo -- 0.143.1</generator>
    <language>ko</language>
    <atom:link href="http://localhost:1313/tags/0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[AWS] Elastic IP (탄력적 IP)의 개념 및 적용</title>
      <link>http://localhost:1313/posts/18/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/18/</guid>
      <description>&lt;p&gt;EIP(Elastic Ip Address)란 인터넷으로 접속이 가능한 공인 IP를 할당하여, 인스턴스에 탈부착할 수 있는 서비스이다. 인스턴스 혹은 네트워크 인터페이스에 연결이 가능하며 삭제 전까지 해당 IP를 유지할 수 있다.EC2 인스턴스 생성 시 공인 IP 사용 설정을 Enable로 변경 (default는 Disable)할 경우 인스턴스 자체에 공인 IP를 할당받을 수 있는데 왜 굳이 Elastic IP를 사용하는 것일까?![](/images/posts/18/스크린샷 2023-10-09 오후 1.56.51.png)인스턴스가 stop 후 재시작될 경우 공인 IP가 변경되는 경우가 발생한다. 인스턴스 자체의 공인 IP가 변경될 경우 큰 문제로 이어질 수 있어EIP를 인스턴스에 연결함으로써 인스턴스의 공인IP를 고정시켜 준다.## 2. Elastic IP 개념 및 특징- 탄력적 IP 주소는 정적이며 시간이 지남에 따라 변경되지 않는다.- 탄력적 IP 주소는 특정 리전에서만 사용할 수 있으며 다른 리전으로 이전할 수 없다.- IPv4 주소의 Amazon 풀 또는 AWS 계정으로 가져온 사용자 지정 IPv4 주소 풀에서 탄력적 IP 주소를 할당할 수 있다. (3-3. EIP 옵션 설정 시 선택 가능)- 탄력적 IP 주소를 사용하려면 먼저 계정에 주소를 할당한 후 인스턴스 또는 네트워크 인터페이스와 연결해야 한다.(3-6. 인스턴스 할당)- 탄력적 IP 주소는 리소스에서 연결 해제했다가 다른 리소스와 다시 연결할 수 있다. 예기치 않은 동작을 방지하려면 변경하기 전에 기존 연결에 이름이 지정된 리소스에 대한 모든 활성 연결이 닫혀 있는지 확인해야 한다. 탄력적 IP 주소를 다른 리소스에 연결한 후 새로 연결된 리소스에 대한 연결을 다시 열 수 있다.- 연결 해제한 Elastic IP 주소는 명시적으로 릴리스(삭제)할 때까지 계정에 할당되어 있기 때문에 실행 중인 인스턴스와 연결되지 않은 탄력적 IP 주소에 대해서는 소액의 시간당 요금이 부과된다 (2. 요금 항목 참고).- 탄력적 IP 주소를 이전에 퍼블릭 IPv4 주소가 있던 인스턴스와 연결하면 인스턴스의 퍼블릭 DNS 호스트 이름이 탄력적 IP 주소에 맞게 변경된다.- Amazon은 퍼블릭 DNS 호스트 이름을 인스턴스 네트워크 외부에서는 인스턴스의 퍼블릭 IPv4 주소 또는 탄력적 IP 주소로 변환하고, 인스턴스 네트워크 내부에서는 인스턴스의 프라이빗 IPv4 주소로 변환한다.- AWS 계정으로 가져온 IP 주소 풀에서 탄력적 IP 주소를 할당하는 경우 해당 IP 주소는 탄력적 IP 주소 한도에 포함되지 않는다.- 탄력적 IP 주소는 특정 네트워크 경계 그룹에서만 사용할 수 있다.퍼블릭(IPv4) 인터넷 주소는 흔치 않은 퍼블릭 리소스 이기 때문에 지역당 5개로 제한되며, 인스턴스 장애 시 주소를 다른 인스턴스로 다시 매핑하는 기능이 필요할때는 EIP를 주로 사용하고, 다른 모든 노드 간 통신은 DNS 호스트명을 사용하는 것을 권장한다. (사용개수 제한은 AWS에 별도 문의하여 최대 사용량을 증가시킬 수 있다.)## 3. 요금- 실행 중인 인스턴스와 연결된 각 추가 IP 주소에 대해 시간당 0.005 USD(비례 할당으로 계산)- 실행 중인 인스턴스와 연결되지 않은 각 탄력적 IP 주소에 대해 시간당 0.005 USD(비례 할당으로 계산)- 매달 처음 100개의 재매핑에 대해 탄력적 IP 주소 재 매핑당 0.00 USD- 매달 100개 이후의 재매핑에 대해 탄력적 IP 주소 재 매핑당 0.10 USD상세 요금은 다음 공식 링크에서 확인 가능하다.&lt;a href=&#34;https://aws.amazon.com/ec2/pricing/on-demand/&#34;&gt;https://aws.amazon.com/ec2/pricing/on-demand/&lt;/a&gt;EC2 온디맨드 인스턴스 요금 – Amazon Web Servicesaws.amazon.com4. 적용#### 4-1. EC2 메뉴에서 Elastic IPs 선택![](/images/posts/18/스크린샷 2023-10-09 오후 2.00.56.png)#### 4-2. Allocate Elastic IP address 선택![](/images/posts/18/스크린샷 2023-10-09 오후 2.02.17.png)### 4-3. 네트워크 경계그룹, IP주소 풀 선택 후 &amp;ldquo;Allocate&amp;quot;선택#### 4-3-1. 네트워크 경계 그룹AWS가 Public 주소를 알리는 가용영역, , Local Zone 또는 Wavelength Zone의 집합이다. Local Zone 및 Wavelength Zone은 AWS 네트워크와 해당 영역의 리소스에 액세스 하는 고객 간의 지연 시간 또는 물리적 거리를 최소화하기 위해 리전의 AZ와 다른 네트워크 경계 그룹을 가질 수 있다.주의 : EIP와 연결될 AWS 리소스는 동일한 네트워크 경계 그룹에 할당되어야 한다.#### 4-3-2. Public IPv4 address pool- [Amazon의 IP 주소 풀(Amazon&amp;rsquo;s pool of IPv4 addresses)] - 특별한 경우가 아니라면 해당 옵션을 선택하여 공인 IP를 할당받으면 된다. IPv4 주소를 Amazon의 IPv4 주소 풀에서 할당하려는 경우이다.- AWS 계정으로 가져오는 퍼블릭 IPv4 주소 - AWS 계정으로 가져온 IP 주소 풀에서 IPv4 주소를 할당하려는 경우. IP 주소 풀이 없는 경우에는 이 옵션을 사용할 수 없다.- [고객 소유 IPv4 주소 풀(Customer owned pool of IPv4 addresses)] - AWS Outpost를 통해 사용할 온프레미스 네트워크에서 생성된 풀에서 IPv4 주소를 할당하려는 경우. AWS Outposts가 없는 경우 이 옵션이 비활성화된다.![](/images/posts/18/스크린샷 2023-10-09 오후 2.03.46.png)### 4-4. EIP 생성이 완료되면 리스트에서 확인이 가능하며, 인스턴스 할당을 위해서 해당 항목을 클릭하여 상세 페이지로 들아간다.![](/images/posts/18/스크린샷 2023-10-09 오후 2.04.45.png)### 4-5. EIP 상세에서 우측 상단 &amp;ldquo;Associate Elastic IP address&amp;quot;를 선택한다.&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/images/posts/18/img_1.png&#34;&gt;### 4-6. AWS 인스턴스와 연결하고 싶다면 인스턴스를 선택, 특정 사설(private) ip와 연결하고 싶다면 IP주소를 입력하면 된다.&amp;ldquo;Allow this Elastic IP address to be reassociated&amp;rdquo; 옵션을 선택하면 해당 EIP를 할당 후 다른 인스턴스로 변경이 가능하다.&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/images/posts/18/img_2.png&#34;&gt;참고&lt;a href=&#34;https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html&#34;&gt;https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html&lt;/a&gt;#AWS #eip #Elastic IPs&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Elastic Search] Elastic Search란? Elastic Search의 개념 및 장단점</title>
      <link>http://localhost:1313/posts/50/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/50/</guid>
      <description>&lt;p&gt;Apache Lucene에 구축되어 배포된 검색 및 분석 엔진이다. 현재 검색엔진을 넘어 보안, 로그분석, Full-text 분석 등 다양한 영역에서 사용되며, Kibana, Logstash, Beats들과 함께 사용된다. 오픈 소스 프로젝트로 활발히 개발되고 있으며, 유닉스, 자바의 기초지식 필요하다. Apache Lucene의 한계를 보완하기 위한 새로운 검색엔진 프로젝트로 시작되었고 Logstash, Kibana와 함께 사용되어 ELK Stack (ES, Logstash, Kibana)라고 불렸으나 2013년 Logstash, Kibana 프로젝트 정식 흡수되었다.## 2. Elastic Stack이란?ES, Logstash, Kibana를 묶은 ELK 서비스이다. 5.0.0 버전부터 Beats를 포함하며 Elastic Stack 이란 이름으로 서비스가 제공되고 있다. 서버로부터 모든 유형의 데이터를 가져와 실시간 검색, 분석, 시각화를 도와주는 Elastic 오픈 소스 서비스 제품이다.&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/images/posts/50/img.png&#34;&gt;### 2-1. Elastic Search- 아파치 루씬(Apache Lucene) 기반의 Full Text로 검색이 가능한 오픈 소스 분석 엔진- 주로 Rest API로 처리- 대량 데이터를 거의 실시간으로 신속하게 저장, 검색, 분석 가능### 2-2. Logstash- 플러그인을 통해 데이터 집계와 보관, 서버 데이터 처리 담당- ES와 상관없이 독자적으로도 사용 가능- 파이프라인으로 데이터를 수집, 필터를 통해 변환 후 Elastic Search로 전송- 입력 - Beats, CloudWatch, Eventlog 등 다양한 입력 지원, 데이터 수집- 필터 - 형식, 복잡성에 상관없이 데이터를 동적으로 변환- 출력 - ES, Email, ECS, Kafka 등 원하는 저장소에 데이터 전송### 2-3. Kibana- 데이터 시각화 도구- 검색 및 aggregation 집계기능을 통해 ES로부터 문서, 집계 결과등을 가져와 웹도구로 시각화- DIscover, Visualize, Dashboard 3개의 기본 메뉴와 다양한 App 들로 구성- 플러그인을 통해 App 설치 가능### 2-4. Beats- 경량 에이전트로 설치- 데이터를 Logstash 또는 ES로 전송- Logstash 보다 경량화 된 서비스- Filebeat, Metricbeat, Packetbeat, Winlogbeat, Heartbeat 등- Libbeat을 통해 직접 구축 가능## 3. Elastic Search의 특징과 장단점### 3-1. 장점#### → 3-1. 실시간분석- 하둡 시스템과 달리 ES 클러스터가 실행되고 있는 동안에는 계속해서 데이터가 입력 (인덱싱) 되고, 동시에 실시간에 가까운 속도로 색인된 데이터의 집계, 검색이 가능#### → 3-2. Full Text 검색 엔진- Lucene은 기본적으로 역파일 색인 구조로 데이터를 저장하며 이를 사용하는 ES도 동일 방식&amp;gt; 역색인 - 일반적인 색인의 목적은 문서의 위치에 대한 index를 생성하여 그 문서에 빠르게 접근하기 위함이지만, 역색인은 문서 내의 문자와 같은(혹은 유사한) 내용들에 대한 매핑 정보를 색인하는 것이다.- 내부적으로는 역파일 색인이라도 사용자 관점에서는 JSON 형식으로 전달- 쿼리문 또는 쿼리에 결과도 모두 JSON 형태로 반환- key-value 형식이 아닌 문서기반으로 되어있어 복잡한 정보를 포함해도 그대로 저장이 가능하여 직관적- 여러 계층 구조의 문서로 저장이 가능하며, 계층 구조로 된 문서도 한 번의 쿼리로 조회 가능#### → 3-3. RESTFul API- Rest API를 기본으로 지원하여 모든 데이터의 조회, 입력, 삭제를 HTTP 프로토콜을 통해 처리 가능#### → 3-4. multitenancy- ES의 데이터들은 index라는 논리 집합 단위로 구성되며 서로 다른 저장소에 분산-저장된다.- 서로 다른 인덱스들을 별도 커넥션 없이 하나의 쿼리로 묶어서 검색, 하나의 출력 결과를 도출한다. (서로 상이한 인덱스일지라도 검색할 필드명만 같으면 여러 인덱스를 동시에 조회 가능)#### → 3-5. 확장성- 분산 구성이 가능, 분산환경에서 데이터는 shard 단위로 분리- 플러그인을 사용한 기능 확장 가능- AWS, MS Azure 같은 클라우드 서비스, Hadoop 플랫폼들과도 연동 가능#### 3-6. 다양한 알고리즘 제공- 점수 기반의 다양한 정확도 알고리즘, 실시간 분석 등의 구현 가능### 3-2. 단점- 색인된 데이터는 내부 commit, flush 등의 프로세스를 거치기에 1초정도 뒤에 검색이 가능- 클러스터의 성능향상을 위해 비용소모가 큰 트랜잭션 롤백이 지원되지 않는다.- 업데이트 요청시 기존 문서를 삭제 후 신규 문서를 재생성하기에 업데이트 비용이 크다.## 4. Elastic Search 구성&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/images/posts/50/img_1.png&#34;&gt;#### Index- 데이터 저장공간- 하나의 물리 노드에 여러 개의 논리 인덱스 생성- 하나의 인덱스가 여러 노드에 분산 저장#### Shard- 색인된 문서는 하나의 인덱스와 그 내부의 여러 개의 파티션(샤드)으로 나뉘어 구성#### Type- 인덱스의 논리적 구조- 6.1부터 인덱스당 하나의 타입만 설정 가능#### Document- 인덱스가 저장되는 최소단위- JSON 포멧으로 저장- RDBMS의 ROW와 동일#### Field- 문서를 구성하기 위한 속성- 하나의 필드는 다수의 데이터 타입 정의 가능- RDBMS의 컬럼과 동일#### Mapping- 문서의 필드, 필드 속성을 정의하고 색인 방법을 정의하는 프로세스## 5. Elastic Search와 RDBMS의 관계익숙한 관계형 데이터베이스와의 유사 기능 관계를 통해 이해해 보면&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/images/posts/50/img_2.png&#34;&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/images/posts/50/img_3.png&#34;&gt;참고&lt;a href=&#34;https://jaemunbro.medium.com/elastic-search-%EA%B8%B0%EC%B4%88-%EC%8A%A4%ED%84%B0%EB%94%94-ff01870094f0&#34;&gt;https://jaemunbro.medium.com/elastic-search-%EA%B8%B0%EC%B4%88-%EC%8A%A4%ED%84%B0%EB%94%94-ff01870094f0&lt;/a&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/indices.html&#34;&gt;https://www.elastic.co/guide/en/elasticsearch/reference/current/indices.html&lt;/a&gt;&lt;a href=&#34;https://velog.io/@hanblueblue/Elastic-Search-1&#34;&gt;https://velog.io/@hanblueblue/Elastic-Search-1&lt;/a&gt;#Elastic Stack #Elastic search&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Linux] 심볼릭 링크 (Symbolic link) 설정하기</title>
      <link>http://localhost:1313/posts/16/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/16/</guid>
      <description>&lt;p&gt;링크를 걸어 원본 파일을 직접 사용하는 것과 같은 효과를 낸다. 특정 폴더에 링크를 걸어 NAS, library 원본 파일을 사용하거나 톰캣 빌듯이 상위경로의 파일을 사용하고자 할 때 사용한다. 심볼릭 링크는 단순히 원본파일을 가리키도록 링크만 연결시켜둔 것으로 원본파일을 가리키기만 하고 있으므로 원본파일의 크기와 무관하며 원본파일이 삭제되어 존재하지 않을 경우에 빨간색으로 링크파일의 원본파일이 없다는 것을 알려준다.## 2. 심볼릭 링크 설정하기&lt;code&gt;ln -s [대상 원본 파일] [새로 만들 파일 이름]-- 파일을 생성 후 링크를 거는 것이 아니라 새로 만들 파일/directory가 없는 채로 링크를 생성을 해야한다.&lt;/code&gt;###     2-1. ln 옵션- s : 심볼릭링크 생성한다.- b : 링크파일 생성 시에 대상파일이 이미 존재하면 백업파일을 만든 후에 링크파일을 생성한다.- d : 디렉토리에 대한 하드링크파일생성을 가능하게 한다.- f : 대상파일이 존재할 경우에 대상파일을 지우고 링크파일을 생성한다.- i : 대상파일이 존재할 경우에 대상파일을 지울건인가를 확인요청한다.- t : 링크파일을 생성할 디렉토리를 지정한다.###      2-2. 심볼릭 링크 생성(directory)![](/images/posts/16/스크린샷 2023-10-09 오전 11.35.53.png)###     2-3. 심볼릭 링크 생성(file)![](/images/posts/16/스크린샷 2023-10-09 오전 11.36.44.png)원본 파일을 못 찾을 경우 빨간색으로 알려준다.![](/images/posts/16/스크린샷 2023-10-09 오전 11.37.03.png)###      2-4. 심볼릭 링크 삭제&lt;code&gt;rm [링크 파일]rm -r [링크 디렉토리]&lt;/code&gt;#Linux #ln #symbolic link #심볼릭 링크&lt;/p&gt;</description>
    </item>
    <item>
      <title>[LLM] Google Cloud Discovery Engine 데이터 스토어 업로드 포맷</title>
      <link>http://localhost:1313/posts/121/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/121/</guid>
      <description></description>
    </item>
    <item>
      <title>[PostgreSQL]  인덱스(INDEX)개념 및 생성, 삭제, 분석, 설계 방법</title>
      <link>http://localhost:1313/posts/5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/5/</guid>
      <description>&lt;h3 id=&#34;1-1-인덱스-조회select--from-pg_indexes-where-tablename--테이블명----테이블명에--필요-1-2-인덱스-생성---단일-인덱스create-index-인덱스명-on-테이블명-using-btree컬럼명---결합-인덱스create-index-인덱스명-on-테이블명-using-btree컬럼명1-컬럼명2---유니크-인덱스create-unique-index-인덱스명-on-table_name-컬럼명-1-3-인덱스-삭제drop-index-인덱스명-1-4-인덱스-사용-빈도-확인select-schemaname-relname-indexrelname-idx_scan-as-idx_scan_cnt-from-pg_stat_user_indexes-order-by-idx_scan-1-5-인덱스-손상-시-재인덱싱reindex-index-인덱스명reindex-table-테이블명reindex-database-데이터베이스명-2-인덱스-란데이터에-색인을-통해-데이터의-위치를-빠르게-찾아주는-역할을-한다-인덱스-설정-없이는-seq-스캔을-통해-테이블-전체를-조회하기에-검색-성능이-저하된다-2-1-테이블-스캔-방식postgresql은-seq-scan-index-scan-bitmap-index-scan-index-only-scan-tid-scan-5가지-스캔-방식을-사용한다-그중-2가지를-확인해-보면---2-1-1-seq-scan-방식---seq-scan은-테이블을-full-scan-하여-전체-데이터를-조회한다--인덱스가-존재하지-않거나-인덱스가-존재하더라도-읽어야-할-범위가-넓은-경우에-선택된다---2-1-2-index-scan-방식---index-scan은-인덱스-leaf-블록에-저장된-키를-이용해서-테이블-레코드를-액세스-하는-방식이다--레코드-정렬-상태에-따라서-테이블-블록-액세스-횟수가-크게-차이-난다다음과-같이-인덱스를-사용할-경우-테이블-레코드에-효과적인-접근이-가능하다-하지만-select-성능은-올라가지만-update-insert-delete시-index-색인정보-갱신을-하기에-시간이-더-소모된다-2-2-인덱스가-적용되지-않는-경우--order-by-인덱스칼럼-1-칼럼-2--복수-키에-대해-order-by-하는-경우--order-by-col1-col2-자체를-인덱스-설정하면-적용가능---where-칼럼-1--x-order-by-인덱스칼럼-2--조건절에-의하여-연속적이지-않게-된-컬럼에-대한-order-by---order-by-인덱스컬럼1-desc-인덱스컬럼2-asc--desc와-asc의-결합사용---group-by-인덱스컬럼1-order-by-인덱스컬럼2--group-by-order-by-컬럼이-서로-다른-경우---order-by-abs인덱스컬럼1--형-변환-이후의-order-by-group-by-인-경우-2-3-인덱스-설계-방법---명확한-이유를-가진-인덱스만-설계-많을수록-좋은-게-아니다---조회-쿼리들을-전체-확인-후-자주-사용하는-컬럼---고유-값-위주의-설계---cardinality가-높을수록-효율적-컬럼별-중복도가-낮을수록-좋다---인덱스-key의-크기는-되도록-작게-설계---pk-join의-대상이-되는-컬럼에-설계--단일-인덱스-여러-개----update-delete가-빈번하지-않은-컬럼---join의-대상이-자주-되는-컬럼---인덱스를-생성할-때-가장-효율적인-자료형은-정수형-자료-가변적-데이터는-비효율적---선택도가-낮을수록-효율적-1015-선택도는-데이터에서-특정-값을-얼마나-잘-선택할-수-있는지에-대한-지표특정-필드값을-지정했을-때-선택되는-레코드-수를-테이블-전체-레코드-수로-나눈-수치-컬럼의-특정-값의-row-수--테이블의-총-row-수--100-컬럼의-값들의-평균-row-수--테이블의-총-row-수--100-2-4-다중-컬럼-인덱스다중-컬럼-인덱스는-두개-이상의-필드를-조합해서-생성한-인덱스이다-다중-컬럼-인덱스는-단일-컬럼-인덱스-보다-더-비효율적으로-indexupdatedelete를-수행하기-때문에-생성에-신중해야-한다-가급적-update가-안되는-값을-선정해야-한다-조건절에-여러개의-조건이-있을시-선행되는-조건과-이를-만족하는-후행되는-조건들을-차례로-함께-index해서-사용한다-2-4-1-다중-컬럼-인덱스-설계-방법--다중-컬럼-인덱스-구성시-컬럼의-순서는-io를-적게-발생시키는-순으로-구성하여야-한다선행-인덱스에서-더-많은-데이터가-필터링될수록-이후-인덱스의-io가-덜-소모된다--인덱스-컬럼을-합쳐-색인하기에-선행-인덱스-컬럼이-조건에-있어야-한다예를-들어create-index-idx_user_sample-on-user-using-btreefirst_name-address-user-테이블에-first_name-address-두컬럼을-대상으로-다중-컬럼-인덱스를-부여한-후select--fromwhere-first_name--junand-address--seoul으로-테이블을-조회할-경우-junseoul에-대한-인덱스를-찾고b-tree-인덱스의-left-to-right-특성대로-address-만으로는-인덱스를-사용할-수-없다-선행되는-조건절인-first_name에-대한-조건에-부합하는-데이터를-기준으로-인덱싱이-되어있다또한create-index-idx_user_sample2-on-user-using-btreefirst_name-last_name-address-first-name-last-name-address로-다중-컬럼-인덱스를-설정할-경우-다음과-같이-인덱스가-사용된다---인덱스-사용select--fromwhere-first_name--junand-last_name--hand-address--seoul---인덱스-미사용select--fromwhere-first_name--junand-address--seoul결론적으로--다중-컬럼-인덱스의-성능은-절대적인-것이-아닌-어떤-데이터를-조회하는지-쿼리를-어떻게-작성하는지에-따라-크게-달라질-수-있기에-확실한-쿼리-플랜-분석-및-설계가-필요하다--postgresql-b-tree-인덱스의-원리-및-특징httpsjunhkangtistorycom6--postgresql-hash-인덱스의-원리-및-특징httpsjunhkangtistorycom7--postgresql-gist인덱스의-원리-및-특징httpsjunhkangtistorycom8--postgresql-sp-gist인덱스의-원리-및-특징httpsjunhkangtistorycom9--postgresql-gin인덱스의-원리-및-특징httpsjunhkangtistorycom10--postgresql-brin-인덱스의-원리-및-특징httpsjunhkangtistorycom11postgresql-b-tree-인덱스의-원리-및-특징postgresql에는-6가지의-인덱스-종류가-있다-각각의-인덱스는-다양한-데이터-탐색을-위해-다른-알고리즘을-사용한다-그중-가장-일반적으로-사용되고-가장-먼저-도입된-알고리즘인-b-tree-인덱스에junhkangtistorycompostgresql-hash-인덱스의-원리-및-특징1-hash-인덱스란-해쉬-인덱스의-기본-아이디어는-hash-function을-통해-작은-숫자를-데이터와-조합하여-integer-형태의-해쉬값-최대-232--4b을-생성하고-해쉬값을-테이블-행-정보tid가-저장될-배열junhkangtistorycompostgresql-gist인덱스의-원리-및-특징1-gist-인덱스란-generalized-search-tree의-약자이며-b-tree와-같은-balanced-search-tree의-형태이다-b-tree인덱스는-정렬된-채로-비교일치의-연산에-최적화된-채로-연결되어있다-하지만-현대의-다양한-데이junhkangtistorycompostgresql-sp-gist인덱스의-원리-및-특징1-sp-gist-인덱스란-space-partitioned-generalized-search-tree의-약자이다-gist인덱스와-같이-지리-좌표-ip주소-데이터-등-복잡한-유형의-데이터를-처리하는-인덱스-유형이다-gist가-b-tree-인덱스를-통해-보junhkangtistorycompostgresql-gin인덱스의-원리-및-특징1-gin-인덱스란-generalized-inverted-index의-약자이다-이전-포스트인-full-text-search에서-사용하는-인덱스의-유형-기본-구조는-b-tree와-유사하지만-저장-형태가-다르다-저장된-요소-자제에-대한-검색junhkangtistorycompostgresql-brin-인덱스의-원리-및-특징1-brin-인덱스란--block-range-index의-약자--page-검색에-도움-되는-메타-데이터를-뽑아서-인덱스를-구성-ex-특정컬럼의-최대최솟값--특정-컬럼이-물리-주소의-일정한-상관관계를-가지는-매우junhkangtistorycom인덱스-index-postgresql&#34;&gt;1-1. 인덱스 조회&lt;code&gt;SELECT * FROM pg_indexes WHERE tablename = &#39;{테이블명}&#39;; -- 테이블명에 &#39;&#39; 필요&lt;/code&gt;### 1-2. 인덱스 생성&lt;code&gt;-- 단일 인덱스CREATE INDEX {인덱스명} ON {테이블명} USING btree({컬럼명});-- 결합 인덱스CREATE INDEX {인덱스명} ON {테이블명} USING btree({컬럼명1}, {컬럼명2});-- 유니크 인덱스CREATE UNIQUE INDEX {인덱스명} ON table_name ({컬럼명});&lt;/code&gt;### 1-3. 인덱스 삭제&lt;code&gt;DROP INDEX {인덱스명};&lt;/code&gt;### 1-4. 인덱스 사용 빈도 확인&lt;code&gt;SELECT schemaname, relname, indexrelname, idx_scan as idx_scan_cnt FROM pg_stat_user_indexes ORDER BY idx_scan;&lt;/code&gt;### 1-5. 인덱스 손상 시 재인덱싱&lt;code&gt;REINDEX INDEX {인덱스명}REINDEX TABLE {테이블명}REINDEX DATABASE {데이터베이스명}&lt;/code&gt;## 2. 인덱스 란?데이터에 색인을 통해 데이터의 위치를 빠르게 찾아주는 역할을 한다. 인덱스 설정 없이는 Seq 스캔을 통해 테이블 전체를 조회하기에 검색 성능이 저하된다.### 2-1. 테이블 스캔 방식Postgresql은 seq scan, index scan, bitmap index scan, index only scan, tid scan 5가지 스캔 방식을 사용한다. 그중 2가지를 확인해 보면,#### ▪  2-1-1. Seq Scan 방식&amp;gt; - Seq Scan은 테이블을 Full Scan 하여 전체 데이터를 조회한다.- 인덱스가 존재하지 않거나, 인덱스가 존재하더라도 읽어야 할 범위가 넓은 경우에 선택된다.#### ▪  2-1-2. Index Scan 방식&amp;gt; - Index Scan은 인덱스 Leaf 블록에 저장된 키를 이용해서 테이블 레코드를 액세스 하는 방식이다.- 레코드 정렬 상태에 따라서 테이블 블록 액세스 횟수가 크게 차이 난다.다음과 같이, 인덱스를 사용할 경우 테이블 레코드에 효과적인 접근이 가능하다. 하지만 select 성능은 올라가지만, update, insert, delete시 index 색인정보 갱신을 하기에 시간이 더 소모된다.### 2-2. 인덱스가 적용되지 않는 경우▪  order by {인덱스칼럼 1}, {칼럼 2} : 복수 키에 대해 order by 하는 경우  (order by col1, col2 자체를 인덱스 설정하면 적용가능)▪   where {칼럼 1} = &amp;lsquo;x&amp;rsquo; order by {인덱스칼럼 2} : 조건절에 의하여 연속적이지 않게 된 컬럼에 대한 order by▪   order by {인덱스컬럼1} desc, {인덱스컬럼2} asc : desc와 asc의 결합사용▪   group by {인덱스컬럼1} order by {인덱스컬럼2} : group by, order by 컬럼이 서로 다른 경우▪   order by abs({인덱스컬럼1}) : 형 변환 이후의 order by, group by 인 경우### 2-3. 인덱스 설계 방법▪   명확한 이유를 가진 인덱스만 설계 (많을수록 좋은 게 아니다.)▪   조회 쿼리들을 전체 확인 후 자주 사용하는 컬럼▪   고유 값 위주의 설계▪   Cardinality가 높을수록 효율적 (=컬럼별 중복도가 낮을수록 좋다)▪   인덱스 key의 크기는 되도록 작게 설계▪   PK, join의 대상이 되는 컬럼에 설계▪  단일 인덱스 여러 개 ▪   Update, delete가 빈번하지 않은 컬럼▪   join의 대상이 자주 되는 컬럼▪   인덱스를 생성할 때 가장 효율적인 자료형은 정수형 자료 (가변적 데이터는 비효율적)▪   선택도가 낮을수록 효율적 (10~15%)* 선택도는 데이터에서 특정 값을 얼마나 잘 선택할 수 있는지에 대한 지표(특정 필드값을 지정했을 때 선택되는 레코드 수를 테이블 전체 레코드 수로 나눈 수치)= 컬럼의 특정 값의 row 수 / 테이블의 총 row 수 * 100= 컬럼의 값들의 평균 row 수 / 테이블의 총 row 수 * 100### 2-4. 다중 컬럼 인덱스다중 컬럼 인덱스는 두개 이상의 필드를 조합해서 생성한 인덱스이다. 다중 컬럼 인덱스는 단일 컬럼 인덱스 보다 더 비효율적으로 INDEX/UPDATE/DELETE를 수행하기 때문에 생성에 신중해야 한다. (가급적 UPDATE가 안되는 값을 선정해야 한다). 조건절에 여러개의 조건이 있을시, 선행되는 조건과 이를 만족하는 후행되는 조건들을 차례로 함께 INDEX해서 사용한다.#### 2-4-1. 다중 컬럼 인덱스 설계 방법▪  다중 컬럼 인덱스 구성시 컬럼의 순서는, IO를 적게 발생시키는 순으로 구성하여야 한다.(선행 인덱스에서 더 많은 데이터가 필터링될수록 이후 인덱스의 I/O가 덜 소모된다.)▪  인덱스 컬럼을 합쳐 색인하기에 선행 인덱스 컬럼이 조건에 있어야 한다.예를 들어&lt;code&gt;CREATE INDEX idx_user_sample ON user USING btree(first_name, address );&lt;/code&gt;user 테이블에 first_name, address 두컬럼을 대상으로 다중 컬럼 인덱스를 부여한 후,&lt;code&gt;SELECT * fromWHERE first_name = &#39;Jun&#39;AND address = &#39;Seoul&#39;&lt;/code&gt;으로 테이블을 조회할 경우 &amp;lsquo;JunSeoul&amp;rsquo;에 대한 인덱스를 찾고,B-Tree 인덱스의 left to right 특성대로, address 만으로는 인덱스를 사용할 수 없다. (선행되는 조건절인 first_name에 대한 조건에 부합하는 데이터를 기준으로 인덱싱이 되어있다.)또한&lt;code&gt;CREATE INDEX idx_user_sample2 ON user USING btree(first_name, last_name, address );&lt;/code&gt;first name, last name, address로 다중 컬럼 인덱스를 설정할 경우 다음과 같이 인덱스가 사용된다.&lt;code&gt;-- 인덱스 사용SELECT * fromWHERE first_name = &#39;Jun&#39;AND last_name = &#39;H&#39;AND address = &#39;Seoul&#39;-- 인덱스 미사용SELECT * fromWHERE first_name = &#39;Jun&#39;AND address = &#39;Seoul&#39;&lt;/code&gt;결론적으로  다중 컬럼 인덱스의 성능은 절대적인 것이 아닌, 어떤 데이터를 조회하는지, 쿼리를 어떻게 작성하는지에 따라 크게 달라질 수 있기에 확실한 쿼리 플랜 분석 및 설계가 필요하다.- &lt;a href=&#34;https://junhkang.tistory.com/6&#34;&gt;[PostgreSQL] B-tree 인덱스의 원리 및 특징&lt;/a&gt;- &lt;a href=&#34;https://junhkang.tistory.com/7&#34;&gt;[PostgreSQL] Hash 인덱스의 원리 및 특징&lt;/a&gt;- &lt;a href=&#34;https://junhkang.tistory.com/8&#34;&gt;[PostgreSQL] GiST인덱스의 원리 및 특징&lt;/a&gt;- &lt;a href=&#34;https://junhkang.tistory.com/9&#34;&gt;[PostgreSQL] SP-GiST인덱스의 원리 및 특징&lt;/a&gt;- &lt;a href=&#34;https://junhkang.tistory.com/10&#34;&gt;[PostgreSQL] GIN인덱스의 원리 및 특징&lt;/a&gt;- &lt;a href=&#34;https://junhkang.tistory.com/11&#34;&gt;[PostgreSQL] BRIN 인덱스의 원리 및 특징&lt;/a&gt;[PostgreSQL] B-tree 인덱스의 원리 및 특징PostgreSQL에는 6가지의 인덱스 종류가 있다. 각각의 인덱스는 다양한 데이터 탐색을 위해 다른 알고리즘을 사용한다. 그중 가장 일반적으로 사용되고, 가장 먼저 도입된 알고리즘인 B-tree 인덱스에junhkang.tistory.com[PostgreSQL] Hash 인덱스의 원리 및 특징1. Hash 인덱스란? 해쉬 인덱스의 기본 아이디어는, hash function을 통해 작은 숫자를 데이터와 조합하여 integer 형태의 해쉬값 (최대 2^32 = 4B)을 생성하고 해쉬값을 테이블 행 정보(TID)가 저장될 배열junhkang.tistory.com[PostgreSQL] GiST인덱스의 원리 및 특징1. GiST 인덱스란? Generalized Search Tree의 약자이며 B-tree와 같은 balanced search tree의 형태이다. B-tree인덱스는 정렬된 채로 비교&amp;amp;일치의 연산에 최적화된 채로 연결되어있다. 하지만 현대의 다양한 데이junhkang.tistory.com[PostgreSQL] SP-GiST인덱스의 원리 및 특징1. SP-GiST 인덱스란? Space-Partitioned Generalized Search Tree의 약자이다. GiST인덱스와 같이 지리, 좌표, ip주소 데이터 등 복잡한 유형의 데이터를 처리하는 인덱스 유형이다. GiST가 B-tree 인덱스를 통해 보junhkang.tistory.com[PostgreSQL] GIN인덱스의 원리 및 특징1. GIN 인덱스란? Generalized Inverted Index의 약자이다. 이전 포스트인 full text search에서 사용하는 인덱스의 유형. 기본 구조는 B-tree와 유사하지만, 저장 형태가 다르다. 저장된 요소 자제에 대한 검색junhkang.tistory.com[PostgreSQL] BRIN 인덱스의 원리 및 특징1. BRIN 인덱스란? ▪ Block range index의 약자 ▪ Page 검색에 도움 되는 메타 데이터를 뽑아서 인덱스를 구성 (ex, 특정컬럼의 최대/최솟값) ▪ 특정 컬럼이 물리 주소의 일정한 상관관계를 가지는 매우junhkang.tistory.com#인덱스 #Index #PostgreSQL&lt;/h3&gt;</description>
    </item>
    <item>
      <title>[PostgreSQL] 2단계 커밋 프로토콜(Two-Phase Commit Protocol), Prepare transaction</title>
      <link>http://localhost:1313/posts/68/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/68/</guid>
      <description>&lt;p&gt;PostgreSQL은 two-phase commit (2PC) 프로토콜을 지원한다. 다수의 분산 시스템 환경에서 모든 데이터베이스가 정상적으로 수정되었음을 보장하는 두 단계 커밋 프로토콜로 분산 트랜잭션에 참여한 모든 데이터베이스가 모두 함께 커밋되거나 롤백되는 것을 보장한다. PostgreSQL의 2단계 트랜잭션은 외부 트랜잭션 관리 시스템에서 사용하기 위해 존재하며 X/Open XA 표준에서 제안된 특징과 모델을 따른다. (사용빈도가 낮은 일부 기능은 구현되지 않았다.) 2단계 커밋은 다음 스탭에 따라 작동된다.&lt;code&gt;Coordinator                                         CohortQUERY TO COMMIT--------------------------------&amp;gt;VOTE YES/NO           prepare*/abort*&amp;lt;-------------------------------commit*/abort*                COMMIT/ROLLBACK--------------------------------&amp;gt;ACKNOWLEDGMENT        commit*/abort*&amp;lt;--------------------------------end&lt;/code&gt;[커밋 요청단계]- PREPARE를 통해 Coordinator가 데이터베이스 각 노드에 커밋을 준비 요청- 각 데이터베이스는 필요 리소스에 LOCK 설정, 로그파일 저장 등 커밋 준비 작업 실행- 준비 과정의 실패/성공 여부 알림[커밋 단계]- 모든 데이터베이스 노드로부터 완료 메시지를 받을 때까지 대기- 한 데이터베이스라도 PREPARE OK를 받지 못하면, 모든 데이터베이스 노드에 롤백 메시지를 보내 해당 작업 롤백- 모든 데이터베이스에서 PREPARE OK를 받으면 모든 데이터베이스 노드에 커밋 메시지를 보내고 모든 작업 커밋짧은 기간의 PREPARED 트랜잭션은 공유 메모리와 WAL에 저장되며 체크포인트의 트랜잭션은 pg_twophase 디렉터리에 기록된다.## 2. PREPARE TRANSACTION### 2-1. PREPARE TRANSACTION란?&lt;code&gt;PREPARE TRANSACTION &#39;foobar&#39;;&lt;/code&gt;PREPARED TRANSACTION 구문은 2단계 커밋을 위해 현재 트랜잭션을 준비 상태로 변경한다. 이 명령어 후에 해당 트랜잭션은 현재 세션과 완전히 분리되며, 해당 트랜잭션의 상태가 디스크에 완전히 저장된다. 그리고 해당 트랜잭션은 데이터베이스가 커밋요청 전에 충돌하더라도 성공적으로 커밋될 확률이 높다.PREPARED TRANSACTION이 성공하면 트랜잭션은 COMMIT PREPARED, ROLLBACK PREPARED로만 커밋/롤백된다. 해당 커맨드는 PREPARED를 실행한 세션 외에 어떤 세션에서도 실행 가능하다.구문을 실행한 세션의 시점에서 봤을 때 PREPARED TRANSACTION과 ROLLBACK 명령어는 큰 차이가 없다. 현재 진행 중인 트랜잭션은 없어지고, PREPARE TRANSACTION의 실제 결과는 보이지 않기 때문이다. (PREPARED COMMIT 후에나 차이를 알 수 있다.) PREPARE TRANSACTION 명령어가 실패한다면, 현재 트랜잭션이 취소되며 ROLLBACK과 동일한 결과를 나타낸다.지금 실행 중인 prepared 트랜잭션은 pg_prepared_xacts에서 확인 가능하다.[pg_prepared_xacts]- TransactionId - 트랜잭션 ID- GID - 유저가 정의한 트랜잭션 이름- Prepared Date - 트랜잭션 생성일, timestamp with timezone- Owner - 트랜잭션 생성자- Database - 해당 데이터베이스 명### 2-2. 주의사항- PREPARE TRANSACTION은 애플리케이션, 혹은 상호 통신하는 세션을 위한 기능이 아니다. 외부 트랜잭션 관리자가 다양한 트랜잭션이나 기타 트랜잭션 리소스에 걸쳐 원자단위의 글로벌 트랜잭션을 수행할 수 있도록 하는 것이 목적이기에, 만약 transaction manager를 쓰는 것이 아니라면 PREPARE TRANSACTION의 사용을 중단해야 한다.- 트랜잭션 내부에서만 사용해야 한다.- 임시 테이블이나 세션의 임시 네임스페이스를 포함한 명령어나 WITH HOLD, LITEN, UNLISTEN, NOTIFY를 PREPARE에 사용하는 것은 불가능하다. 해당 기능들은 현재세션과 너무 타이트하기 연결되어 있어 트랜잭션 사용에 유용하지 않다.- 런타임 파라미터를 변경한다면, PREPARE TRANSACTION 이후에도 적용되며 COMMIT PREPARED, ROLLBACK PREPARED의 영향을 받지 않는다. 이러한 측면에서 PREPARED TRANSACTION은 롤백보다는 커밋에 더 가깝다.- 클라이언트가 사라지면 종료되지 않은 채로 트랜잭션이 남을 수 있고, PREPARE 스탭만 백업이 복구되면서 트랜잭션을 닫는 스탭이 없어 계속 유지될 수도 있다. PREPARE 구문을 사용한다면, 트랜잭션 매니저를 통해 해당 트랜잭션들을 주기적으로 관리해주어야 한다.- PREPARE 구문이 계속 열려있을 경우 Lock 같은 주요 시스템 자원을 계속 잡고 있을 수 있고, 트랜잭션 ID를 계속 유지하고 있기에 vacuum 시에 사용되지 않는 dead tuple 임에도 정리되지 않을 수 있다.## 3. COMMIT/ROLLBACK PREPARE&lt;code&gt;ROLLBACK PREPARED transaction_id;COMMIT PREPARED &#39;foobar&#39;;&lt;/code&gt;- PREPARE 상태의 트랜잭션을 커밋/롤백시킨다.- 커밋/롤백을 위해서는 해당 트랜잭션을 실행시킨 유저와 동일하거나, superuser권한이 있어야 한다.- 트랜잭션이 실행된 세션과 동일한 세션에 있을 필요는 없다.- 트랜잭션 블록 안에서 사용이 불가능하다. (PREPARED TRANSACTION이 즉시 커밋/롤백된다.)PostgreSQL Extension 기능이며, 외부 트랜잭션 관리 시스템에서 사용하기 위해 만들어졌으며, 트랜잭션 매니저와 함께 사용하는 것을 권장한다.&lt;a href=&#34;https://www.postgresql.org/docs/9.6/sql-rollback-prepared.html&#34;&gt;https://www.postgresql.org/docs/9.6/sql-rollback-prepared.html&lt;/a&gt;&lt;a href=&#34;https://www.postgresql.org/docs/9.6/sql-prepare-transaction.html&#34;&gt;https://www.postgresql.org/docs/9.6/sql-prepare-transaction.html&lt;/a&gt;&lt;a href=&#34;https://www.postgresql.org/docs/9.6/sql-commit-prepared.html&#34;&gt;https://www.postgresql.org/docs/9.6/sql-commit-prepared.html&lt;/a&gt;&lt;a href=&#34;https://www.highgo.ca/2020/01/28/understanding-prepared-transactions-and-handling-the-orphans/&#34;&gt;https://www.highgo.ca/2020/01/28/understanding-prepared-transactions-and-handling-the-orphans/&lt;/a&gt;#PostgreSQL #2pc #prepared&lt;/p&gt;</description>
    </item>
    <item>
      <title>[PostgreSQL] Hash 인덱스의 원리 및 특징</title>
      <link>http://localhost:1313/posts/7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/7/</guid>
      <description>&lt;p&gt;해쉬 인덱스의 기본 아이디어는, hash function을 통해 작은 숫자를 데이터와 조합하여 integer 형태의 해쉬값 (최대 2^32 = 4B)을 생성하고 해쉬값을 테이블 행 정보(TID)가 저장될 배열의 인덱스 값으로 사용하는 것이다. 이 배열의 각 요소를 해시 테이블 버킷(hash table bucket)이라고 한다. 데이터 조회 시, hash function을 통해 생성된 key가 포함된 bucket을 찾고, 그 bucket만 확인하면 실제 데이터의 위치를 바로 확인할 수 있다. 데이터의 크기에 상관없이 인덱스의 크기가 작고 검색이 빠르다. 1개의 데이터를 조회하는 시간은 O(1)로 빠르지만 해쉬 테이블 내의 값들은 정렬이 되어있지 않기 때문에 범위 비교나 부정형 비교가 포함된 조건에서는 인덱스를 사용할 수 없다. Hash function이 버킷 단위로 소스 값을 더 균일하게 분배할수록 효율이 좋다.### ▪ 1-1. Collision그러나 아무리 좋은 해시 함수라도 다른 키 값에 대해 동일한 해쉬값을 리턴하는 경우가 있고 이런 경우를 &amp;ldquo;충돌(collision)&amp;ldquo;이라고 한다.  하나의 버킷은 서로 다른 TID를 저장할 수 있으므로 인덱스에서 얻은 실제 값을 재확인하여야 한다. 예를들어, 256개의 버킷이 있다면, 모든 문자열의 첫 글자로 해쉬값을 생성할 수 있다. 이 경우 동일한 문자로 시작하는 모든 문자열이 동일한 해쉬값을 가진 채로 한 버킷으로 들어갈 것이고, 실제 버킷에서 값이 찾아진 후에도 TID의 검증이 계속 필요할 것이며, 해싱의 의미가 없어질 것이다.이를 방지하기위해  Hash function은 hashcode - TID 쌍을 순차적으로 저장하여 효율적으로 bucket 내 동일 hash codes들 중에 정확히 일치하는 TID만을 찾는다.## 2. Hash 인덱스 구조&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/images/posts/7/img_1.png&#34;&gt;- Meta page - Root, 첫 번째 page, 인덱스 정보 포함- Bucket pages - 인덱스의 메인 page, &amp;ldquo;hash code - TID&amp;rdquo; 쌍으로 데이터를 저장- Overflow pages - bucket pages와 동일한 구성, 한 page가 버킷에 부족할 때 사용됨- Bitmap pages - overflow pages를 계속해서 추적하며  clear 한 지, 다른 버킷에서 재사용 가능한지 확인한다해쉬 인덱스의 크기는 줄어들지 않는다. 인덱스 열을 삭제하여도 한번 할당된 bucket은 os로 반환되지 않는다. Vacuuming, reindexing을 통해 전체 삭제 후 처음부터 다시 인덱싱은 가능하다.#### ▪ 결론- Hash 인덱스는 단일 값 검색에서는 효율적인 성능을 보인다. (B-Tree에 비해 작은 인덱스 size, O(1))- 범위, 부정형 조건에 대한 검색에서는 사용 불가하다.- 한번 생성된 버킷은 인덱스를 제거하여도 초기화 전에는 메모리에 반환되지 않는다.참고 : &lt;a href=&#34;https://postgrespro.com/blog/pgsql/4161321&#34;&gt;https://postgrespro.com/blog/pgsql/4161321&lt;/a&gt;#Index #PostgreSQL #Hash Index&lt;/p&gt;</description>
    </item>
    <item>
      <title>[PostgreSQL] MVCC (Multi-Version Concurrency Control)</title>
      <link>http://localhost:1313/posts/15/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/15/</guid>
      <description>&lt;p&gt;동시성 제어를 위해 lock을 사용하는 대부분의 다른 데이터베이스 시스템과 달리 Postgres는 다중 버전 모델(multiversion model)을 사용하여 데이터 일관성을 유지한다. 각 트랜잭션이 데이터베이스를 쿼리 하는 동안 데이터의 현재 상태에 관계없이 얼마 전의 데이터 스냅샷을 볼 수 있음을 의미한다. 데이터를 쿼리 하기 위해 트랜잭션을 만들었다면 해당 Transaction은 데이터의 스냅샷을 보고 있는 것이다.동일한 행에 서로 다른 트랜잭션이 동시에 업데이트를 시도할 때, 일관성 없는 데이터가 조회되지 않도록 트랜잭션을 보호하여 각 데이터베이스 세션에 대한 트랜잭션 격리를 제공한다. Multiversion과 Lock model의 주요 차이점은 MVCC에서 데이터 read를 위해 획득한 lock과 데이터 쓰기를 위해 획득한 lock이 충돌하지 않는다는 것이다. (따라서 read와 write는 서로 block 하지 않는다.) 이러한 방식을 통해서 Reading 하는 작업에 대해서 Lock을 걸지 않기에 높은 성능을 얻을 수 있게 된다.### 1-1. Postgresql Lock에 대한 상세 설명&lt;a href=&#34;https://junhkang.tistory.com/4&#34;&gt;2023.09.11 - [Postgresql] - Postgresql Lock이란? (조회 및 kill, Dead lock)&lt;/a&gt;Postgresql Lock이란? (조회 및 kill, Dead lock)1. Lock 확인방법 SELECT PSAT.RELNAME, PL.LOCKTYPE, PL.PID, PL.MODE, PL.GRANTED FROM PG_LOCKS PL, PG_STAT_ALL_TABLES PSAT WHERE PL.RELATION = PSAT.RELID 2. Lock Kill 방법 SELECT PG_CANCEL_BACKEND([PID]) SELECT PG_TERMINATE_BACKEND([PID]) Lock 리스junhkang.tistory.com## 2. PostgreSQL의 MVCCPostgreSQL에서는 record를 tuple이라고 한다. PostgreSQL에서는 멀티버전에 대한 정보를 하나의 Page ( Table )에서 관리하고 있다. 모든 테이블에는 System Columns을 가지고 있고 이들은 미리 정의된 컬럼들로 내부 동작에 사용된다. 이 컬럼 중 mvcc를 구현하게 해주는 것이 xmin, xmax 컬럼이다.&amp;gt; xmin – Tuple을 insert 하거나 update 하는 시점의 Transaction ID를 갖는 메타데이터xmax – Tuple을 delete 하거나 update 하는 시점의 Transaction ID를 갖는 메타데이터신규 insert, update시 xmin에 현재 transaction id를 넣고 xmax에는 null 값을 넣는다. delete, update시 이전 tuple의 xmax에는 작업을 수행한 transaction id 값을 넣는다. 이를 통해 트랜잭션이 시작된 시점의 Transaction ID와 같거나 작은 Transacion ID를 가지는 데이터를 읽는다. (xmin과 xmax의 범위를 통해 해당 트랜잭션이 조회할 수 있는 데이터인지를 판단한다.)&lt;code&gt;xmin  | xmax  |  value-------+-------+-----100 |  120 | A102 |  120 | B110 |  134 | C115 |    0 | D115 |  120 | E&lt;/code&gt;&amp;gt; [Transaction ID 별 조회 가능한 데이터]Transaction 101에서는 ATransaction 109에서는 A, BTransaction 112에서는 A, B, CTransaction 117에서는 A, B, C, D, E하나의 page에 이전 tuple들이 그대로 존재하기 때문에, row가 삭제되어도 용량은 그대로 차지하는 경우가 있다. 쿼리 성능 또한 지속적으로 떨어지게 된다. 따라서 PostgreSQL에서는 Vacuum 작업을 진행해주어야 한다.Vacuum에 대한 상세 개념은 해당 포스트에서 확인할 수 있다.&lt;a href=&#34;https://junhkang.tistory.com/17&#34;&gt;2023.10.09 - [Postgresql] - [PostgreSQL] Vacuum 개념 및 적절한 사용&lt;/a&gt;[PostgreSQL] Vacuum 개념 및 적절한 사용1. Vacuum 이란? Vacuum은 postgresql에서 dead tuple이 차지하는 저장공간을 회수한다. 일반적으로 Postgresql에서 update, delete tuple 은 물리적으로 삭제되지 않으며 vacuum이 완료될 때까지 계속 존재한다. (updatjunhkang.tistory.com[참고]&lt;a href=&#34;https://techblog.woowahan.com/9478/&#34;&gt;https://techblog.woowahan.com/9478/&lt;/a&gt;&lt;a href=&#34;https://www.postgresql.org/docs/9.1/ddl-system-columns.html&#34;&gt;https://www.postgresql.org/docs/9.1/ddl-system-columns.html&lt;/a&gt;&lt;a href=&#34;https://www.postgresql.org/docs/7.1/mvcc.html&#34;&gt;https://www.postgresql.org/docs/7.1/mvcc.html&lt;/a&gt;#Lock #Vacuum #PostgreSQL #MVCC&lt;/p&gt;</description>
    </item>
    <item>
      <title>[PostgreSQL] SP-GiST인덱스의 원리 및 특징</title>
      <link>http://localhost:1313/posts/9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/9/</guid>
      <description>&lt;p&gt;Space-Partitioned Generalized Search Tree의 약자이다. GiST인덱스와 같이 지리, 좌표, ip주소 데이터 등 복잡한 유형의 데이터를 처리하는 인덱스 유형이다. GiST가 B-tree 인덱스를 통해 보관 데이터를 세분화할 때, 위계적 순서를 따라야 하기에, 이를 보완하기 위해 만들어진 유형으로, GiST로 분리된 공간을 다시 한번 공간 단위로 나누어 관리하는 개념이다. SP-GiST는 겹치지 않는 영역으로 재귀적 분할을 할 수 있는 구조에 적합하다. 기본적으로 SP-GiST는 다양한 데이터 유형, 복잡한 쿼리를 지원하도록 설계되었다.### 1-1. SP-GiST 인덱스 생성&lt;code&gt;CREATE INDEX idx_spgist_example ON example_table USING spgist (column1);&lt;/code&gt;### 1-2. 장점&amp;gt; 다양한 종류의 데이터 타입에 사용 가능 : 기하학, IP, 다른 복잡한 데이터 타입복잡한 쿼리에 사용 가능 : 복잡한 데이터구조, 쿼리에 사용 적합하도록 설계빠른 검색 효율### 1-3. 단점&amp;gt; 복잡한 구현 방법 : btree/hash 에 비해 구현이 복잡하다.느린 업데이트 : SP-GiST index는 업데이트가 느리다, 복잡한 알고리즘인 만큼 특정 데이터 변경시 인덱스의 업데이트가 느리다.한정된 쿼리 유형 : 복잡한 유형의 쿼리에 특화 되어있다보니 =, &amp;lt;등 간단한 타입의 비교에는 고려되지 않을 수 있다.### 1-4. 그렇다면 SP-GiST는 GiST인덱스와 어떻게 다를까?#### ▪ 1-4-1. Operator&amp;gt; ▪ GiST에 비해 SP-GiST를 지원하는 operator가 적다. (SP-GiST 지원 Operator는 아래에서 확인가능)(GiST는 (k) NN searches를 포함한 모든 operator 지원을 받는다.)#### ▪ 1-4-2. 인덱스 생성 시간&amp;gt; ▪ GiST 인덱스의 생성시간은 데이터 증가에 따라 비선형적이지만 안정적으로 증가한다.▪ SP-GiST 인덱스는 적은 데이터일 경우 빠르지만, 몇 억 건이 넘어갈 경우 GiST에 비해 현저히 떨어지는 속도를 보인다.#### ▪ 1-4-3. 데이터 밀집도에 따른 효율성&amp;gt; ▪ GIST는 기하학적 구조의 공간 분포와 토폴로지에 크게 민감하지 않다.▪ SP_GIST는 공간 분할(Spatial Partitioning)로 인해 중첩되지 않는 지오메트리에 가장 효과적이며 공간적으로 균일한 분포에 대한 검색에 효율적이다.데이터 사이즈, 구조, 사용하는 쿼리 등에 따라 인덱스의 효율성이 달라질 수 있어, 실제 데이터로 GiST, SP-GiST의 성능테스트가 꼭 필요하다.## 2. 지도 / 좌표 형태의 데이터 인덱싱다음과 같이 위도/경도 데이터로 조회를 시도할 시 효율적이다&lt;code&gt;SELECT city_nameFROM locationsWHERE ST_DWithin(ST_MakePoint(:longitude, :latitude), ST_MakePoint(longitude, latitude), :distance);&lt;/code&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/images/posts/9/img.png&#34;&gt;지도의4분 할로 지속적으로 나눈다. 각각의 사각형이 index page 역할을 한다나눠진 부분을 좀 더 상세히 보면&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/images/posts/9/img_1.png&#34;&gt;다음 좌표에서 (2,7) 위에 존재하는 좌표들을 찾고 싶다면&lt;code&gt;select * from points where p &amp;gt;^ point &#39;(2,7)&#39;&lt;/code&gt;(4,4)를 (2,7)과 비교하여 더 큰 좌표가 존재할 수 있는 영역을 확인한다.1 사분면의 중심좌표인 (6,6)으로 다시 비교하여 더 큰 좌표가 존재할 수 있는 영역을 확인한 후 다음과 같은 인덱스 구조를 생성한다.&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/images/posts/9/img_2.png&#34;&gt;## 3. Built-in Operator ClassNameIndexable OperatorsOrdering Operatorsbox_ops(box,point)&amp;amp;&amp;amp;&amp;gt; (box,box)&amp;raquo; (box,box)@&amp;gt; (box,box)&lt;del&gt;= (box,box)&amp;amp;&amp;amp; (box,box)&amp;amp;|&amp;amp;&amp;gt; (box,box)|&amp;raquo; (box,box)inet_ops&amp;raquo; (inet,inet)&amp;raquo;= (inet,inet)= (inet,inet)&amp;lt;&amp;gt; (inet,inet)&amp;gt; (inet,inet)&amp;gt;= (inet,inet)&amp;amp;&amp;amp; (inet,inet)kd_point_ops|&amp;raquo; (point,point)(point,point)&amp;raquo; (point,point)&lt;/del&gt;= (point,point)poly_ops(polygon,point)&amp;amp;&amp;amp;&amp;gt; (polygon,polygon)&amp;raquo; (polygon,polygon)@&amp;gt; (polygon,polygon)&lt;del&gt;= (polygon,polygon)&amp;amp;&amp;amp; (polygon,polygon)&amp;amp;|&amp;raquo; (polygon,polygon)|&amp;amp;&amp;gt; (polygon,polygon)quad_point_ops|&amp;raquo; (point,point)(point,point)&amp;raquo; (point,point)&lt;/del&gt;= (point,point)range_ops= (anyrange,anyrange)&amp;amp;&amp;amp; (anyrange,anyrange)@&amp;gt; (anyrange,anyelement)@&amp;gt; (anyrange,anyrange)&amp;raquo; (anyrange,anyrange)&amp;amp;&amp;amp;&amp;gt; (anyrange,anyrange)-|- (anyrange,anyrange)text_ops= (text,text)&amp;gt; (text,text)&amp;gt;= (text,text)~~~&amp;gt;=~ (text,text)&lt;del&gt;&amp;gt;&lt;/del&gt; (text,text)^@ (text,text)참고&lt;a href=&#34;https://www.postgresql.org/docs/current/spgist-builtin-opclasses.html&#34;&gt;https://www.postgresql.org/docs/current/spgist-builtin-opclasses.html&lt;/a&gt;&lt;a href=&#34;https://gis.stackexchange.com/questions/374091/when-to-use-gist-and-when-to-use-sp-gist-index&#34;&gt;https://gis.stackexchange.com/questions/374091/when-to-use-gist-and-when-to-use-sp-gist-index&lt;/a&gt;#Index #PostgreSQL #SP-GIST&lt;/p&gt;</description>
    </item>
    <item>
      <title>[PostgreSQL] Trigger, Procedure, Function (history 관리하기)</title>
      <link>http://localhost:1313/posts/3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/3/</guid>
      <description>&lt;p&gt;특정 테이블에 insert, update가 수행될 경우 무조건 내역에 &amp;ldquo;insert&amp;quot;를 하는 간단한 트리거 생성 예제이다.#### 1-1. 함수를 실행할 트리거 생성&lt;code&gt;create trigger trigger_save_historyafter insert or update on Afor each rowexecute procedure trigger_insert();&lt;/code&gt;#### 1-2. 실제 insert문이 실행되는 함수&lt;code&gt;CREATE OR REPLACE FUNCTION trigger_insert()returns triggerAS $$DECLAREBEGINinsert into B(id, values, date)values(new.id, new.values, current_timestamp());return NULL;END; $$LANGUAGE &#39;plpgsql&#39;;&lt;/code&gt;하지만 특정 table에 insert, delete, update에 따라 서로 다른 테이블에 이력을 보관하거나, 기존 이력을 업데이트하는 등서로 다른 행위에 대한 트리거가 필요한 경우가 있다.그럴경우 다음 예제처럼 TG_OP을 통해 데이터베이스에 UPDATE, INSERT, DELETE를 분기하는 것이 가능하다. 또한 old, new를 통해 delete의 삭제 전 값, update의 업데이트 전, 후 값을 각각 사용할 수 있다.## * 수행되는 SQL에 따라 별도 history 저장 트리거 생성 예제&lt;code&gt;CREATE OR REPLACE FUNCTION TRIGGER_INSERT()RETURNS TRIGGERLANGUAGE PLPGSQLAS$function$BEGINIF (TG_OP = &#39;UPDATE&#39;) THENinsert into update_history(id, values, date)values(new.id, new.values, current_timestamp());return NULL;ELSIF (TG_OP = &#39;INSERT&#39;) THENinsert into insert_history(id, values, date)values(new.id, new.values, current_timestamp());return NULL;ELSIF (TG_OP = &#39;DELETE&#39;) THENinsert into delete_history(id, values, date)values(new.id, old.values, current_timestamp());return NULL;END IF;RETURN NULL;END$function$;&lt;/code&gt;## 1. 트리거(Trigger) 란 무엇일까?특정 SQL이 실행될 때 자동으로 실행되는 객체이다. 테이블의 변경 감지 및 로깅에 많이 사용되며, 데이터만 전달 후 연산 자체를 DB에 넘기기에 부하 및 확장성을 고려하여 적용하여야한다. 단일 함수를 생각할 경우 서버 로직보다 트리거 함수가 빠르고 쉽게 적용되는 경우가 있지만, 트리거가 너무 많은 경우 문제발생 원인파악과 유지보수가 힘들다. 또한 코드가 복잡하여 작성자 외 트리거 내용을 분석하기 힘들다. 또한, 트리거 함수가 동작할 때, 트리거의 영향을 받는 모든 개체들은 트랜잭션이 열린 상태로 유지된다. 즉, 트리거 연산 시간만큼 트랜잭션 lock 타임도 길어진다. 부적합한 트리거는 성능을 크게 저하시킬 수 있다. 그래서 복잡한 로직을 처리하기보다는, 간단한 실행에 사용하고, 트리거 작성 시 정확한 목적과 동작방식을 문서화하는 것이 중요하다.&amp;gt; - 특정 SQL이 실행될 때 자동으로 실행되는 객체이다- 트리거 내에서 COMMIT / ROLLBACK 사용불가하다.- 쿼리문장별, ROW별로 실행가능하다.- OLD / NEW 를 통해 실행된 쿼리의 이전, 이후값 접근 가능하다.- 특정 PROCEDURE / FUNCTION을 실행시킬 수 있다.## 2. 프로시저(Procedure)와 함수(Function)는 무엇일까?자주 사용되는 특정기능을 모듈화 시켜놓은 것을 함수(function) 또는 프로시저(procedure)라고 하는 것을 알고 있다. PostgreSQL에서 정확히 어떻게 사용되며 차이점은 무엇일까?### 2-1. FUNCTION- 주로 클라이언트에서 실행 (어플리케이션에서 호출)- 리턴값 필수- 저장해서 쓰는 프로시져 ( 인자만 변경하여 자유롭게 재사용 가능 )- 반복작업을 줄여주며 여러개의 쿼리문을 묶어서 실행 가능- 특정 계산을 수행### 2-2. PROCEDURE- 리턴값은 필요에 따라 반환- DB서버에서 실행(처리속도 빠름)- 미리 컴파일된 SQL 명령어의 집합- 특정 작업을 수행### 2-3. 차이점 비교함수(Function)프로시저(Procedure)특정 계산 수행특정 작업 수행리턴값 필수 O리턴값 필수 X리턴값이 1개여야만 함리턴값이 여러개일 수 있음Client에서 실행 (어플리케이션에서 호출)Server에서 실행(DB)단독 문장 구성 불가단독 문장 구성 가능수식내에서만 사용 가능수식 내에서 사용 불가#function #Trigger #PostgreSQL #Procedure&lt;/p&gt;</description>
    </item>
    <item>
      <title>[PostgreSQL] Vacuum 개념 및 적절한 사용</title>
      <link>http://localhost:1313/posts/17/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/17/</guid>
      <description>&lt;p&gt;Vacuum은 postgresql에서 dead tuple이 차지하는 저장공간을 회수한다. 일반적으로 Postgresql에서 update, delete tuple 은 물리적으로 삭제되지 않으며 vacuum이 완료될 때까지 계속 존재한다.(update, delete 시 tuple의 순환은 MVCC 개념에서 확인할 수 있다.)&lt;a href=&#34;https://junhkang.tistory.com/15&#34;&gt;2023.10.06 - [Postgresql] - [PostgreSQL] MVCC (Multi-Version Concurrency Control)&lt;/a&gt;[PostgreSQL] MVCC (Multi-Version Concurrency Control)1. MVCC란? 동시성 제어를 위해 lock을 사용하는 대부분의 다른 데이터베이스 시스템과 달리 Postgres는 다중 버전 모델(multiversion model)을 사용하여 데이터 일관성을 유지한다. 각 트랜잭션이 데이터junhkang.tistory.com그렇기 때문에 특히 자주 업데이트되는 테이블의 경우 주기적인 Vacuum 수행이 필요하다. Vacuum은 특정 테이블에 한해서도 실행이 가능하고, 테이블을 지정하지 않는다면 전체 테이블 (권한을 보유한)에 대해서 실행된다.## 2. Vacuum 명령어&lt;code&gt;-- DB 전체 full vacuumvacuum full analyze;-- DB 전체 간단하게 실행vacuum verbose analyze;-- 해당 테이블만 간단하게 실행vacuum analyze [테이블 명];-- 특정 테이블만 full vacuumvacuum full [테이블 명];&lt;/code&gt;## 3. Vacuum 상세 옵션&lt;code&gt;VACUUM [ ( option [, ...] ) ] [ table_and_columns [, ...] ]VACUUM [ FULL ] [ FREEZE ] [ VERBOSE ] [ ANALYZE ] [ table_and_columns [, ...] ]where option can be one of:FULL [ boolean ]FREEZE [ boolean ]VERBOSE [ boolean ]ANALYZE [ boolean ]DISABLE_PAGE_SKIPPING [ boolean ]SKIP_LOCKED [ boolean ]INDEX_CLEANUP { AUTO | ON | OFF }PROCESS_MAIN [ boolean ]PROCESS_TOAST [ boolean ]TRUNCATE [ boolean ]PARALLEL integerSKIP_DATABASE_STATS [ boolean ]ONLY_DATABASE_STATS [ boolean ]BUFFER_USAGE_LIMIT [ size ]and table_and_columns is:table_name [ ( column_name [, ...] ) ]&lt;/code&gt;## 4. Vacuum analyzeVacuum analyze 는 vacuum 후 테이블 별로 analyze를 수행(통계정보 수집)하기에 유지보수에 원활하다.Postgresql 버전업을 수행한 후, 인덱스 및 테이블 튜닝이 완료된 쿼리 (평균 소요시간 0.8초 이내)가 5분 이상 소모되어 서비스에 문제를 일으키는 상황이 발생하였다. Vacuum analyze를 사용해 통계 정보를 조정 후 플랜이 정상적으로 작동하는 것을 확인하였다.## 5. Vacuum without FullFull 옵션 없이 vacuum 은 단순히 tuple을 삭제후 공간을 확보하여 재사용 가능하게 한다. 이 작업은 일반적은 read/write와 동시에 실행될 수 있으며 배타적 lock이 발생하지 않는다. 그러나 일반적으로 추가 공간이 OS로 반환되지 않고, 동일 테이블에 재사용가능 상태로 반환된다.  인덱스를 처리하기위해 여러 개의 CPU를 사용할 수 있으며, 이를 parallel Vacuum이라고 한다.## 6. Vacuum Fullvacuum full은 테이블 전체 내용을 추가 공간 없이 새로운 디스크파일에 다시 작성한다. 미사용 space는 OS로 반환된다. 일반적인 vacuum 보다 훨씬 시간이 오래 걸리며, 해당 테이블에 lock 이 발생하기에 운영 중인 테이블에 실행 시 주의하여야 한다. Vacuum은 transaction 블럭 내에서는 사용이 불가능하다. Gin 인덱스의 경우 대기중인 인덱스 생성까지 완료된다.(Gin 인덱스에 대한 개념은 다음 포스트에서 확인 가능하다.)&lt;a href=&#34;https://junhkang.tistory.com/10&#34;&gt;2023.09.13 - [Postgresql] - [PostgreSQL] GIN인덱스의 원리 및 특징&lt;/a&gt;[PostgreSQL] GIN인덱스의 원리 및 특징1. GIN 인덱스란? Generalized Inverted Index의 약자이다. 이전 포스트인 full text search에서 사용하는 인덱스의 유형. 기본 구조는 B-tree와 유사하지만, 저장 형태가 다르다. 저장된 요소 자제에 대한 검색junhkang.tistory.com## 7. Vacuum의 적절한 사용Vacuum의 수동 실행이아니더라도 postgresql 에는 autovacuum launcher가 상시 수행되고 있어 dead tuple이 임계치에 도달하거나 table, tuple의 age가 누적되어 임계치에 도달하였을 때 auto vacuum이 실행된다. Postgresql에서는 Autovacuum 활성화를 권장하고 있다.Vacuum Full의 경우 테이블 자체의 락이 발생하기에 사용에 주의하여야 하며, 보통 사용자가 없는 시간대나 시스템 영향도가 낮은 시간대에 실행하나, 해당 지표만으로 Vacuum 주기를 설정하는 것이 정답은 아니다. Vacuum이 너무 잦은 것도 Vacuum 부하로 쿼리성능을 저하시키기에 좋지 않고, 영향도가 너무 낮은 시간을 찾기 위해 너무 드물게 수행하면 삭제할 tuple 및 작업이 많아져 오히려 큰 부하를 유발할 수 있다. 그러므로 상세 파라미터 튜닝을 통해 현재 운영 중인 시스템에 맞는 Vacuum주기를 찾는 것이 중요하다.참고&lt;a href=&#34;https://www.postgresql.org/docs/current/sql-vacuum.html&#34;&gt;https://www.postgresql.org/docs/current/sql-vacuum.html&lt;/a&gt;&lt;a href=&#34;https://techblog.woowahan.com/9478/&#34;&gt;https://techblog.woowahan.com/9478/&lt;/a&gt;#Vacuum #PostgreSQL&lt;/p&gt;</description>
    </item>
    <item>
      <title>[PostgreSQL] Visibility Map(가시성 맵)의 개념, 원리, 생명주기 및 정보 확인 방법</title>
      <link>http://localhost:1313/posts/79/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/79/</guid>
      <description>&lt;p&gt;Visibility Map은 트랜잭션에서 데이터에 접근할 때 어떤 데이터가 가시적인지(모든 트랜잭션에서 읽을 수 있는지), 안정적인지 (동결된 튜플인지) 판별하는데 도움을 준다. 데이터 접근 시 불필요한 I/O작업을 줄여주고, 데이터베이스가 어떤 페이지를 직접 접근할 수 있는지를 빠르게 판단함으로써 시스템의 효율적을 올려주는 역할을 한다.## 2. Visibility Map(가시성 맵)의 데이터 관리Visibility Map은 데이터를 주요 데이터와는 별도의 파일(fork)에 _vm 접미사를 붙여 관리한다. 예를 들어 예를 들어 employees 테이블이 있다고 하면 테이블의 Visibility Map은 별도의 포크에 저장된다. 이 포크의 이름은 파일 노드 번호에 _vm 접미사를 붙여 구성되며, 예를 들어 파일 노드번호가 12345인 경우 VM 파일은 12345_vm으로 저장된다. 데이터에는 해당 테이블의 page가 모든 트랜잭션에 보이는지, 동결된 튜플만을 포함하는지 등의 정보를 저장한다. 데이터베이스가 employees 테이블을 조회할 때, 가시성 맵을 먼저 확인한다. 만약 쿼리가 접근하려는 pages가 모든 트랜잭션에게 보이는 상태라고 확인되면, 시스템은 데이터에 더 빠르게 접근한다. 불필요한 버전검사나 락을 안 해도 되기에 성능이 향상된다.## 3. Visibility Map(가시성 맵)의 원리Visiblity Map은 힙 pages당 2개의 비트를 별도로 저장한다. 첫 번째 비트가 설정되어 있으면, 해당 페이지가 모두 visible(가시적) 한 상태이고, 이는 vacuum이 필요한 튜플을 포함하지 않는다는 뜻이다. 이는 인덱스 영역의 tuple만을 사용하여 index-only-scan으로 쿼리를 조회할 때도 사용된다. index-only-scan은 해당 포스트에서 확인 가능하다.&lt;a href=&#34;https://junhkang.tistory.com/70&#34;&gt;2024.03.13 - [Postgresql] - [PostgreSQL] Index-Only 스캔과 Covering 인덱스, Index-only스캔의 효율적인 사용&lt;/a&gt;[PostgreSQL] Index-Only 스캔과 Covering 인덱스, Index-only스캔의 효율적인 사용1. Index-Only Scans PostgreSQL의 모든 인덱스는 &amp;ldquo;보조(Secondary)&amp;rdquo; 인덱스이다. 각 인덱스는 테이블의 메인 데이터 영역(테이블의 heap 영역)과 분리되어서 저장된다. 그렇기 때문에 일반적인 인덱스 스캔에junhkang.tistory.com두 번째 bit가 설정되어 있다면 모든 pages의 튜플이 frozen(동결된) 상태라는 뜻이다. 이 상태에선 일반적인 vacuum은 물론 anti-wraparound vacuum도 동작시킬 필요가 없다.anti-wraparound-vacuum - 전체 데이터베이스를 검사하여 트랜잭션 ID가 안전한 범위 내에 있는지 확인하여, 필요에 따라 조정하며 트랜잭션 ID의 오버플로우를 방지한다. 트랜잭션 ID에 대한 상세 내용은 해당 포스트에서 확인 가능하다.&lt;a href=&#34;https://junhkang.tistory.com/67&#34;&gt;2024.03.08 - [Postgresql] - [PostgreSQL] 트랜잭션(Transaction)의 작동원리&lt;/a&gt;[PostgreSQL] 트랜잭션(Transaction)의 작동원리1. 기본 트랜잭션의 개념 및 원리 트랜잭션의 기본 개념과 사용 방법은 다음 포스트에서 확인이 가능하다. 2023.10.10 - [Postgresql] - [PostgreSQL] 트랜잭션(Transaction)의 개념 및 사용 [PostgreSQL] 트랜잭션(Tjunhkang.tistory.comVisiblity Map의 2가지 비트는 최대한 보수적으로 해석된다. 1, 2 번째 비트가 설정되어 있을 경우에는 무조건 참이지만, 비트가 설정되지 않을 경우에는 참 일수도 거짓일 수도 있다.## 4. Visibility Map(가시성 맵)의 생명주기Visiblity Map의 비트는 vacuum에 의해서만 설정된다. 데이터베이스 내의 pages에 vacuum 작업이 수행되면 관련 Visiblity Map의 비트가 설정이 되고, 해당 pages가 모든 트랜잭션에서 완전히 가시적임을 표시하며, 더 이상 vacuum 안 해도 됨을 나타낸다. 그 후에 pages의 데이터가 하나라도 수정(update, insert, delete 등) 될 경우, VM의 비트는 초기화된다. 데이터의 상태가 변경되었기에 vacuum 작업 대상에 포함시켜야 함을 나타낸다.## 5. Visibility Map(가시성 맵) 정보 확인pg_visibility 함수를 사용해서 vm에 저장된 정보를 확인할 수 있다.- pg_visibility_map(relation regclass, blkno bigint, all_visible OUT boolean, all_frozen OUT boolean) returns record- 해당 테이블, 해당 블록의 모든 VM의  visible, frozen 비트 조회- pg_visibility(relation regclass, blkno bigint, all_visible OUT boolean, all_frozen OUT boolean, pd_all_visible OUT boolean) returns record - 해당 테이블, 해당 블록의 모든 VM의  visible, frozen 비트 조회 + PD_ALL_VISIBLE 비트- pg_visibility_map(relation regclass, blkno OUT bigint, all_visible OUT boolean, all_frozen OUT boolean) returns setof record - 해당 테이블의 모든 블록의 VM의  visible, frozen 비트 조회- pg_visibility(relation regclass, blkno OUT bigint, all_visible OUT boolean, all_frozen OUT boolean, pd_all_visible OUT boolean) returns setof record - 해당 테이블의 모든 블록의 VM의  visible, frozen 비트 조회 + PD_ALL_VISIBLE 비트- pg_visibility_map_summary(relation regclass, all_visible OUT bigint, all_frozen OUT bigint) returns record - VM에 연관 있는 테이블의 visible 페이지 수량, frozen 페이지 수량 확인- pg_check_frozen(relation regclass, t_ctid OUT tid) returns setof tid - VM에 frozen으로 마킹되어 있는 pages 중 non-frozen 튜플의 TID, 존재해서는 안 되는 경우로, 뭔가 조회가 된다면 VM에 문제가 있는 것- pg_check_visible(relation regclass, t_ctid OUT tid) returns setof tid - VM에 visible으로 마킹되어 있는 pages 중 non-visible 튜플의 TID, 존재해서는 안 되는 경우로, 뭔가 조회가 된다면 VM에 문제가 있는 것- pg_truncate_visibility_map(relation regclass) returns void - 해당 테이블의 VM을 truncate 한다. VM에 문제가 있는 경우 강제로 재설정이 필요할 때 사용. 해당 테이블의 첫 번째 vacuum이 실행될 때 재생성되며, 그전까지는 모든 VM이 모두 0 값으로 유지참고&lt;a href=&#34;https://www.postgresql.org/docs/16/storage-vm.html&#34;&gt;https://www.postgresql.org/docs/16/storage-vm.html&lt;/a&gt;&lt;a href=&#34;https://www.postgresql.org/docs/16/pgvisibility.html&#34;&gt;https://www.postgresql.org/docs/16/pgvisibility.html&lt;/a&gt;#PostgreSQL #Visibility Map #가시성 맵&lt;/p&gt;</description>
    </item>
    <item>
      <title>[PostgreSQL] 명시적 JOIN 절로 플래너(Planner) 제어, 성능 향상</title>
      <link>http://localhost:1313/posts/44/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/44/</guid>
      <description>&lt;p&gt;PostgreSQL은 쿼리 Planner가 가장 효율적인 쿼리 플랜을 세워 쿼리를 실행시킨다. 이번 포스트는 쿼리 Planner가 플랜을 검색하는 과정을 의도적으로 제한하여 플랜 검색 시간을 단축시키는 방법에 대한 내용이다. 쿼리 선택지를 제한함으로써 시간을 줄이지만, 그만큼 모든 경우를 비교하는 것이기 아니라서 최고의 플랜을 찾을 수 없기에, 테이블 scan 방식 및 인덱스 등 쿼리의 작동방식을 명확히 이해한 후 설정이 필요하며, 설정전 성능비교, 설정 후의 데이터 증감에 따른 지속적인 모니터링이 필요하다.## 2. 플래너의 작동### 2-1. JOINPlanner의 작동방식을 보기 위해 간단한 조인 쿼리를 확인해 보자&lt;code&gt;SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;&lt;/code&gt;PostgreSQL 플래너는 조인 순서를 자유롭게 정할 수 있다.- a.id = b.id 조건으로 A, B테이블을 먼저 조인 후에 C테이블을 조인- b.ref = c.id 조건으로 B, C테이블을 먼저 조인 후에 A테이블을 조인- A, C를 조인 후에 B테이블 조인 (A, C의 조인을 최적화하는 조건이 없기에 비효율적)중요한 점은, 모든 방식이 동일한 결과를 가져오지만, 실행 cost에는 엄청난 차이가 난다는 것이다. 그래서 planner는 가장 효율적인 쿼리 플랜을 찾는다. 사실 쿼리가 2&lt;del&gt;3개의 테이블만 참조한다면, 고려할 조인방식이 그리 많지 않다. 그러나 테이블 수가 증가할수록 조인 순서의 선택지는 확연히 증가한다. 10개 정도의 테이블이 조인될 경우 모든 경우의 수를 철저히 검색하는 것은 실용적이지 않고, 테이블 수가 6&lt;/del&gt;7개만 되어도 plan을 선택하는데 굉장히 오랜 시간이 걸릴 수 있다.너무 많은 테이블이 참조될 때, PostgreSQL planner는 검색하는 플랜의 경우의 수를 제한하는 genetic 확률적 검색으로 전환한다.이 경우, 검색하는 플랜의 수가 줄어들기에 검색시간은 줄어들지만, 최고의 플랜을 찾지 못할 수도 있다.### 2-2. OUTER-JOIN다음과 같은 outer 조인에서 planner의 조인 순서 선택지는 확연히 줄어든다.&lt;code&gt;SELECT * FROM a LEFT JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);&lt;/code&gt;이전 일반 join과 조건은 똑같이 적용되었지만, 작동방식은 현저히 다르다. 기존 일반 조인은 B와 C를 조인한 결과와 일치하지 않는 A의 각 로우들은 생략되어야 하고 outer join은 A의 각 로우들이 생략되지 않는다.그래서 planner의 선택지는 다음으로 줄어든다.- a.id = b.id 조건으로 A, B테이블을 먼저 조인 후에 C테이블을 조인- b.ref = c.id 조건으로 B, C테이블을 먼저 조인 후에 A테이블을 조인- A, C를 조인 후에 B테이블 조인 (A, C의 조인을 최적화하는 조건이 없기에 비효율적)Planner는 해당 쿼리의 유효한 플랜이 1개로 인식하고, 선택지가 1개이기에 plan을 세우는데 적은 시간이 든다.반면에 다음과 같은 경우에 planner는 2개 이상의 plan이 유효하다고 판단할 수도 있다.&lt;code&gt;SELECT * FROM a LEFT JOIN b ON (a.bid = b.id) LEFT JOIN c ON (a.cid = c.id);&lt;/code&gt;- a.id = b.id 조건으로 A, B테이블을 먼저 조인 후에 C테이블을 조인- b.ref = c.id 조건으로 B, C테이블을 먼저 조인 후에 A테이블을 조인- a.cid = c.id 조건으로 A, C테이블을 먼저 조인 후에 B테이블을 조인현재는 FULL JOIN만이 테이블 간의 조인 순서 제한하지만, 대부분의 LEFT JOIN, RIGHT JOIN은 조인 순서가 재배열될 수 있다.명시적인 INNER JOIN (INNER JOIN, CROSS JOIN 등)은 구조적으로 FROM 절에 테이블 입력 순서와 의미적으로 동일하게 실행되므로 조인순서를 제약하지 않는다. (영향을 받지 않는다.)대부분의 JOIN이 순서를 완전히 제약하지 않지만, PostgreSQL 플래너가 모든 JOIN절을 조인 순서를 제약하도록 별도 지시할 수 있다. 예를 들어 다음 세 쿼리는 논리적으로 동일하다.&lt;code&gt;SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;SELECT * FROM a CROSS JOIN b CROSS JOIN c WHERE a.id = b.id AND b.ref = c.id;SELECT * FROM a JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);&lt;/code&gt;그러나 planner에게 조인 순서를 정하도록 하면, 2,3번 쿼리가 첫 번째 쿼리보다 plan을 세우는데 더 적은 시간이 걸리며 실제 플랜도 다르게 나온다. 이 차이는 테이블이 3개 있을 때는 그리 크지 않지만, 많은 테이블을 대상으로 할 때는 굉장히 효율적이다.planner가 명시적 join에 제시된 테이블 조인 순서를 따르게 하려면 join_collapse_limit 매개변수를 1로 설정하면 된다.아니면 일반 FROM절 리스트에서 JOIN 구문을 추가해도 되기 때문에, plan 검색시간을 줄이기 위해 파라미터를 조정하여 조인 순서를 완벽하게 제한시킬 필요는 없다.예를 들어&lt;code&gt;SELECT * FROM a CROSS JOIN b, c, d, e WHERE ...;&lt;/code&gt;join_collapse_limit=1 옵션을 주면, 해당 쿼리는 다른 선택지에 대한 고려 없이 A와 B를 우선적으로 조인하도록 강제한다. 그렇기 때문에이 예제에서는 가능한 조인 순서가 5배로 줄어들게 된다. (5! -&amp;gt; 4!)이런 방식으로 planner의 계획 검색을 제한하는 것은 planning 시간을 줄여주고 planner를 좋은 쿼리플랜으로 유도하는데 도움이 된다.만약 planner가 안 좋은 조인 순서를 기본으로 선택하였다면, JOIN 문법을 통해 더 좋은 join 순서로 유도할 수 있다. 다만 작성 후 성능비교 및 플랜확인은 필수이다.### 2-3. Subqueryplanning시간이 영향을 주는 유사한 예로는, 서브쿼리를 상위 쿼리에 포함시키는 경우이다. 다음 간단한 서브쿼리를 확인해 보자.&lt;code&gt;SELECT *FROM x, y,(SELECT * FROM a, b, c WHERE something) AS ssWHERE somethingelse;&lt;/code&gt;일반적으로 Planner는 서브쿼리를 부모쿼리에 포함시키기에 다음과 같다.&lt;code&gt;SELECT * FROM x, y, a, b, c WHERE something AND somethingelse;&lt;/code&gt;이러한 쿼리가 보통 서브쿼리를 따로 planning 하는 것보다 효율적이다. (예를 들어, 부모쿼리의 where 절은 x를 A에 먼저 조인시켜 A의 많은 row를 제거함으로써 서브쿼리의 결과와 전체 조회를 실행하는 것을 피할 수 있다.) 그러나 동시에, planning 시간이 증가한다.&amp;gt; 2가지의 3개의 테이블을 조인하는 경우의 수[2 x (3!)] -&amp;gt; 5개의 테이블을 조인하는 경우의 수 [5!]더 많은 테이블을 참조할 경우, 가능한 조인 방식의 수가 기하급수적으로 늘어남으로써 큰 차이가 된다. planner는 subquery를 상위 쿼리에 포함시킴으로써 조인 방식의 경우의 수가 너무 커지는 문제를 방지하기 위해  from_collapse_limit의 파라미터 값보다 최종 조인될 테이블의 수가 많을 경우 서브쿼리를 상위쿼리에 합치지 않는다. 이 그렇기에 run-time 파라미터를 수정함으로써 planning 시간과 plan의 퀄리티를 조절하여 사용할 수 있다.## 3. from_collapse_limit, join_collapse_limit 설정from_collapse_limit와 join_collapse_limit  은 비슷한 역할을 하기에 네이밍이 비슷하게 되어있다. from_collapse_limit는 서브쿼리 사용 시 하위 쿼리를 상위쿼리에 포함시키는 조건을 제어하고, join_collapse_limit는 조인 테이블의 수에 따른 테이블 축소 관계의 최대 수를 제어한다. 일반적으로 두 파라미터의 값은 똑같이 설정하거나(명시적 조인과 서브쿼리가 비슷하게 행동하게 하기 위해) 아니면 join_collapse_limit을 1로 세팅한다.(명시적 조인의 순서를 컨트롤하고 싶을 때) 그러나 planning 시간과 run time 시간을 적절하게 조정하기 위해 다른 값을 부여할 수 있다.### 3-1. from_collapse_limit (integer)- planner는 FROM 절 테이블 개수가 파라미터 값보다 작을 경우 서브쿼리를 부모쿼리로 재배열한다.- 적은 값들은 planning 시간을 줄여주지만 최적의 쿼리 plan을 찾을 수 없을 수도 있다.- 기본 값은 8이다.### 3-2. join_collapse_limit (integer)- planner는 FROM 절 테이블 개수가 파라미터 값보다 작을 경우 명시적인 JOIN절을 다시 구성한다.- 작은 값일수록 planning 시간을 줄여주지만, 최적의 쿼리 플랜을 찾을 수 없을 수도 있다.- 기본값은 from_collapse_limit과 동일한 값이며 대부분의 경우에 적절한 값이다.- 해당값을 1로 설정하는 것은 명시적 Join절의 순서 변환 없이 그대로 사용하게 한다.- 쿼리가 항상 이상적인 쿼리 플랜을 선택하는 것이 아니기 때문에, 쿼리를 통해 변수를 일시적으로 1로 설정한 후 원하는 조인순서를 명시적으로 지정할 수 있다.## 4. 적용테스트 결과 FROM절의 순서를 변경함으로써 PostgreSQL Planner의 계획대상을 변경하는 방법은 두 가지가 있다.### 4-1. join_collapse_limit 파라미터의 값을 1로 설정이 경우 from절의 순서에 맞게 플랜이 변경됨을 확인할 수 있다.### 4-2. 서브쿼리에 OFFSET을 추가하여 서브 쿼리 축소를 방지한다.다음 두쿼리는 결과는 같지만, 명시적 JOIN 절을 사용하여 Planner의 조인 순서를 변경한 케이스이다.&lt;code&gt;select a.*from a, b, cwhere a.id = b.idand b.id  = c.id;&lt;/code&gt;![](/images/posts/44/스크린샷 2023-11-08 오후 4.47.46.png)-&amp;gt; a와 b 테이블을 먼저 조인한 후 c 테이블 조인&lt;code&gt;select *from bcross join lateral(select a.*from a, cwhere a.id = c.id offset 0) as foo;&lt;/code&gt;![](/images/posts/44/스크린샷 2023-11-08 오후 4.48.10.png)-&amp;gt; a와 c 테이블을 먼저 조인한 후 b 테이블 조인## 5. 결론from_collapse_limit, join_collapse_limit 파라미터를 통해 조인 및 서브쿼리 사용 시 쿼리 planner의 플랜 선택지를 조정하여 plan 선택시간을 줄일 수 있다. 다만 제한한 조건 내에 최상의 쿼리 플랜이 없을 경우 최적의 쿼리를 찾을 수 없기에, scan, index, 테이블의 크기 등에 따른 상관관계를 명확이 이해하고 추가해야 하며, 설정 전의 충분한 플랜 분석, 설정 후의 데이터 증감에 따른 지속적인 모니터링 및 튜닝이 필요하다.참고&lt;a href=&#34;https://www.postgresdba.com/bbs/board.php?bo_table=C05&amp;amp;wr_id=201&#34;&gt;https://www.postgresdba.com/bbs/board.php?bo_table=C05&amp;amp;wr_id=201&lt;/a&gt;&lt;a href=&#34;https://www.postgresql.org/docs/current/explicit-joins.html&#34;&gt;https://www.postgresql.org/docs/current/explicit-joins.html&lt;/a&gt;#planner #성능향상 #PostgreSQL&lt;/p&gt;</description>
    </item>
    <item>
      <title>[PostgreSQL] 윈도우 함수(Window Functions)의 개념, 성능 및 사용법 (over, sum/rank/ntitle/cume_dist 등...)</title>
      <link>http://localhost:1313/posts/40/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/40/</guid>
      <description>&lt;p&gt;윈도우 함수는 행과 행 간의 관계를 쉽게 정의하기 위해 만든 함수이다. 이 기능은 일반 집계함수의 연산과 유사하지만, 일반 집계함수가 행 각각을 단일 그룹화해서 출력하는 반면에, 윈도우 함수는 각각의 행들이 그룹화되지 않으며 별도의 ID를 가진다. 그렇기에 윈도우 함수는 현재 row의 정보보다 더 많은 정보에 접근이 가능하다. 예를 들면 다음과 같다.&amp;gt; 일반집계함수 : COUNT() + GROUP BY-&amp;gt; 그룹별 1개의 행 출력 (그룹 개수만큼 출력, 자르기 + 집약)윈도우집계함수 : COUNT() OVER (PARTITION BY) -&amp;gt; ID개수만큼 행 출력 (행의 개수가 줄어들지 않는다, 자르기)다음의 공식문서 예제를 보며 윈도우 함수가 어떻게 작동하는지 알아보자. 임직원의 월급, 부서, 직원번호가 포함된 empsalary 테이블이 있다.&lt;code&gt;SELECT depname, empno, salary, avg(salary) OVER (PARTITION BY depname) FROM empsalary;depname  | empno | salary |          avg-----------+-------+--------+-----------------------develop   |    11 |   5200 | 5020.0000000000000000develop   |     7 |   4200 | 5020.0000000000000000develop   |     9 |   4500 | 5020.0000000000000000develop   |     8 |   6000 | 5020.0000000000000000develop   |    10 |   5200 | 5020.0000000000000000personnel |     5 |   3500 | 3700.0000000000000000personnel |     2 |   3900 | 3700.0000000000000000sales     |     3 |   4800 | 4866.6666666666666667sales     |     1 |   5000 | 4866.6666666666666667sales     |     4 |   4800 | 4866.6666666666666667(10 rows)&lt;/code&gt;첫 3개의 컬럼은 테이블의 데이터를 바로 사용하는 것이고, row 당 1개의 값을 가지고 있다. 4번째 컬럼은 같은 부서명의 ROW 끼리의 평균 월급을 나타낸다. (비윈도우 함수의 avg 함수와 동일하지만, over 구문을 사용할 경우 윈도우 함수로 취급받고, window frame 상에서 연산될 수 있게 해 준다.)윈도우 함수는 함수명, 혹은 변수 뒤에 항상 over를 바로 뒤에 붙여 사용한다. over 구문은 쿼리의 row들이 윈도우 함수에 의해 정확히 어떻게 분할되어 작동하는지에 대한 결정을 내린다. over 내의 partition by 구분은 동일한 값을 공유하는 groups 혹은 partitions으로 행을 분할한다. 이렇게 분할된 파티션 상에서 각 행과 동일한 파티션에 속하는 행끼리 연산하게 된다. over 내에 order by를 통해 윈도우 함수에 통과시킬 row의 순서를 정할 수 있다.&lt;code&gt;SELECT depname, empno, salary,rank() OVER (PARTITION BY depname ORDER BY salary DESC)FROM empsalary;depname  | empno | salary | rank-----------+-------+--------+------develop   |     8 |   6000 |    1develop   |    10 |   5200 |    2develop   |    11 |   5200 |    2develop   |     9 |   4500 |    4develop   |     7 |   4200 |    5personnel |     2 |   3900 |    1personnel |     5 |   3500 |    2sales     |     1 |   5000 |    1sales     |     4 |   4800 |    2sales     |     3 |   4800 |    2(10 rows)&lt;/code&gt;rank 함수는 해당 파티션 당 order by 값에 맞는 숫자 형태의 순위를 나타낸다. rank는 over 절에 의해서만 결정되기에 명시적인 매개 변수가 추가로 필요하지 않다.윈도우 함수는 from 절의 테이블에서 where, group by 그리고 having 절로 필터링된 &amp;ldquo;가상 테이블&amp;quot;의 행을 대상으로 작동하기에 조건에 부합하지 않아 제거된 row는 윈도우 함수 내에서 사용되지 않는다. 쿼리에 다양한 over 절을 사용하여 데이터를 분할할 수 있지만, 이 가상 테이블에 정의된 row를 대상으로 동일하게 작동한다. 행의 순서가 중요하지 않은 경우, order by를 생략해도 되는 것처럼, 단일 파티션이 전체 row를 포함하는 경우 partition by를 생략할 수도 있다.### 1-1. Window frame윈도우 함수에 관한 중요한 개념 중 하나는 window frame이다. window frame이라고 불리는 row의 집합이 파티션 내에 존재한다. 몇몇 윈도우 함수는 전체 파티션이 아닌, window frame의 row에 대해서만 동작한다. 기본적으로 ORDER BY를 사용하면 frame은 시작 행부터 현재 행까지의 정보로만 구성되며, order by 가 생략되면, 기본 frame은 파티션 내의 전체 row로 이루어진다. 다음 sum의 예제를 보면&lt;code&gt;SELECT salary, sum(salary) OVER () FROM empsalary;salary |  sum--------+-------5200 | 471005000 | 471003500 | 471004800 | 471003900 | 471004200 | 471004500 | 471004800 | 471006000 | 471005200 | 47100(10 rows)&lt;/code&gt;over 절에 order by가 없기에, window frame은 파티션 전체와 같고, 각 sum은 전체 테이블을 조회하여 일반 집계 함수와 동일한 결과를 가진다. 하지만 order by 가 들어갈 경우 결과가 달라진다. 아래 쿼리는 월급의 최저값 ROW부터 현재 ROW까지 (파티션의)의 합계이다.&lt;code&gt;SELECT salary, sum(salary) OVER (ORDER BY salary) FROM empsalary;salary |  sum--------+-------3500 |  35003900 |  74004200 | 116004500 | 161004800 | 257004800 | 257005000 | 307005200 | 411005200 | 411006000 | 47100(10 rows)&lt;/code&gt;### 1-2. 제약조건위도우 함수는 SELECT와 ORDER BY 절에서만 허용된다. group by, having, where 절 같은 곳에서는 사용이 불가능하다.논리적으로 해당 조건들을 모두 조회한 후에 작동하기 때문이다.그리고 윈도우 함수는 비윈도우집계함수 이후에 실행된다. 즉 윈도우 함수의 인수에 일반 집합 함수 호출을 포함하는 것은 가능하지만, 그 반대의 경우는 불가능하다. 만약 윈도우 함수의 연산 후에 filter 혹은 group by를 할 경우, 서브쿼리를 사용해야 한다. 아래와 같이 사용하면 내부 쿼리의 순위가 3 이하인 row 들만 보여준다.&lt;code&gt;SELECT depname, empno, salary, enroll_dateFROM(SELECT depname, empno, salary, enroll_date,rank() OVER (PARTITION BY depname ORDER BY salary DESC, empno) AS posFROM empsalary) AS ssWHERE pos### 1-3. WINDOW AS쿼리가 만약에 다수의 윈도우 함수를 포함한다면, 각각이 OVER문으로 작성하는 것이 가능하지만, 여러 함수에 대해 동일한 윈도우 설정 동작을 하는 경우 중복되고 에러가 발생하기 쉽다. 이럴 경우 WINDOW에 해당하는 레퍼런스를 설정하고 해당 값을 over에서 사용 이 가능하다.&lt;/code&gt;SELECT sum(salary) OVER w, avg(salary) OVER wFROM empsalaryWINDOW w AS (PARTITION BY depname ORDER BY salary DESC);&lt;code&gt;### 1-4. 성능윈도우 함수를 사용할 경우 집계, 순위 등의 쿼리를 편하게 사용할 수 있고, 테이블의 스캔 횟수도 훨씬 줄어든다. 다만 파티션 내 다른 행과 현재행의 관계정보로 다루어지기에, 윈도우 함수를 사용할 시 기본적으로 정렬하는 과정에서 자원이 소모된다. 테이블 및 데이터 정보에 따라 달라지겠지만, 분포율이 5~7%정도 되는 1200만 건의 데이터를 기준으로 윈도우 함수와 group by 정렬을 비교해 보았다.![](/images/posts/40/img_1.png)![](/images/posts/40/스크린샷 2023-10-31 오후 1.51.46.png)실제로 윈도우 함수를 포함한 경우 sort 과정에 자원이 많이 소모되어 데이터가 많을 경우 오히려 비윈도우 함수보다 효율이 좋지 않았다. 따라서 기능의 편의성 외에도 데이터의 양이나 테이블 구조에 맞춰 윈도우 함수를 사용하고, 서브쿼리나 조건절 튜닝을 통해 스캔해야할 행의 갯수를 줄인 후 사용하는 방법을 고려해야 한다.## 2. 윈도우 함수의 종류 및 사용법### 2-1. 일반집계함수- SUM - 파티션별 윈도우의 합계&lt;/code&gt;SELECT MGR, ENAME, SAL, SUM(SAL) OVER (PARTITION BY MGR ORDER BY SAL RANGE UNBOUNDED PRECEDING) as MGR_SUMFROM EMP;&lt;code&gt;- MAX - 파티션별 윈도우의 최댓값&lt;/code&gt;SELECT MGR, ENAME, SAL, MAX(SAL) OVER (PARTITION BY MGR) as MGR_MAXFROM EMP;&lt;code&gt;- MIN - 파티션별 윈도우의 최솟값&lt;/code&gt; SELECT MGR, ENAME, HIREDATE, SAL, MIN(SAL) OVER(PARTITION BY MGR ORDER BY HIREDATE) as MGR_MINFROM EMP;&lt;code&gt;- AVG - 파티션별 윈도우의 평균값&lt;/code&gt;SELECT MGR, ENAME, HIREDATE, SAL, ROUND (AVG(SAL) OVER (PARTITION BY MGR ORDER BY HIREDATE ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING)) as MGR_AVGFROM EMP;&lt;code&gt;- COUNT - 파티션별 윈도우의 카운트&lt;/code&gt;SELECT ENAME, SAL, COUNT(*) OVER (ORDER BY SAL RANGE BETWEEN 50 PRECEDING AND 150 FOLLOWING) as SIM_CNTFROM EMP;&lt;code&gt;### 2-2. 그룹 내 행 순서 함수- FIRST_VALUE - 파티션별 윈도우에 가장 먼저 나오는 값&lt;/code&gt;SELECT DEPTNO, ENAME, SAL, FIRST_VALUE(ENAME) OVER (PARTITION BY DEPTNO ORDER BY SAL DESC ROWS UNBOUNDED PRECEDING) as DEPT_RICHFROM EMP;&lt;code&gt;- LAST_VALUE - 파티션별 윈도우에 가장 나중에 나오는 값&lt;/code&gt;SELECT DEPTNO, ENAME, SAL, LAST_VALUE(ENAME) OVER ( PARTITION BY DEPTNO ORDER BY SAL DESC ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING) as DEPT_POORFROM EMP;&lt;code&gt;- LAG - 파티션별 윈도우의 이전 몇 번째 행의 값&lt;/code&gt;SELECT ENAME, HIREDATE, SAL, LAG(SAL) OVER (ORDER BY HIREDATE) as PREV_SALFROM EMPWHERE JOB = &amp;lsquo;SALESMAN&amp;rsquo;;&lt;code&gt;- LEAD - 파티션별 윈도우의 이후 몇번째 행의 값&lt;/code&gt;SELECT ENAME, HIREDATE, LEAD(HIREDATE, 1) OVER (ORDER BY HIREDATE) as &amp;ldquo;NEXTHIRED&amp;quot;FROM EMP;&lt;code&gt;### 2-3. 그룹 내 순위함수- RANK - 파티션 내 전체 윈도우에 대한 순위, 동일 값에 대해서는 동일한 순위, 그 다음 값은 순위는 동일한 순위 만큼 증가된 채로 부여 (ex. 1,1,1,4,5,6,7...)&lt;/code&gt;SELECT JOB, ENAME, SAL,RANK( ) OVER (ORDER BY SAL DESC) ALL_RANK,RANK( ) OVER (PARTITION BY JOB ORDER BY SAL DESC) JOB_RANKFROM EMP;&lt;code&gt;- DENSE_RANK - 파티션 내 전체 윈도우에 대한 순위, 동일 값에 대해서는 동일한 순위, 그 다음 값은 순위는 동일한 순위에 상관없이 다음값 부여 (ex. 1,1,1,2,3,4,5...)&lt;/code&gt;SELECT JOB, ENAME, SAL, RANK( ) OVER (ORDER BY SAL DESC) RANK, DENSE_RANK( ) OVER (ORDER BY SAL DESC) DENSE_RANKFROM EMP; &lt;code&gt;- ROW_NUMBER - 파티션 내 전체 윈도우에 대한 순번, 동일한 값이어도 고유한 순위 부여&lt;/code&gt;SELECT JOB, ENAME, SAL, RANK( ) OVER (ORDER BY SAL DESC) RANK, ROW_NUMBER() OVER (ORDER BY SAL DESC) ROW_NUMBERFROM EMP; &lt;code&gt;### 2-4. 그룹 내 비율 함수- RATIO_TO_REPORT - 파티션 내 전체 SUM에 대한 컬럼별 백분율 소수점 값&lt;/code&gt;SELECT ENAME, SAL, ROUND(RATIO_TO_REPORT(SAL) OVER (), 2) as R_RFROM EMPWHERE JOB = &amp;lsquo;SALESMAN&amp;rsquo;; &lt;code&gt;- PERCENT_RANK - 파티션별 윈도우에서 가장 먼저 나오는 것은 0, 제일 마지막에 나오는 것은 1로 나타낸 후 값에 상관없이 행의 순서만으로의 백분율 값&lt;/code&gt;SELECT DEPTNO, ENAME, SAL, PERCENT_RANK() OVER (PARTITION BY DEPTNO ORDER BY SAL DESC) as P_RFROM EMP; &lt;code&gt;- CUME_DIST - 파티션별 윈도우의 전체 건수에서 현재 행보다 작거나 같은 건에 대한 누적 백분률 값&lt;/code&gt;SELECT DEPTNO, ENAME, SAL, CUME_DIST() OVER (PARTITION BY DEPTNO ORDER BY SAL DESC) as CUME_DISTFROM EMP; &lt;code&gt;- NTITLE - 파티션별 전체 건수를 Argument로 N등분한 값&lt;/code&gt;SELECT ENAME, SAL, NTILE(4) OVER (ORDER BY SAL DESC) as QUAR_TILEFROM EMP ;`참고윈도우 함수별 기능 및 예제 - &lt;a href=&#34;http://www.gurubee.net/lecture/2382&#34;&gt;http://www.gurubee.net/lecture/2382&lt;/a&gt;윈도우 함수(WINDOW FUNCTION)제6절 윈도우 함수(WINDOW FUNCTION)WINDOW FUNCTION 종류그룹 내 순위함수.3.1 RANK 함수3.2 DENSE_RANK 함수3.3 ROW_NUMBER 함수일반 집계 함수3.4 ..www.gurubee.net윈도우 함수 공식 문서 - &lt;a href=&#34;https://www.postgresql.org/docs/current/tutorial-window.html&#34;&gt;https://www.postgresql.org/docs/current/tutorial-window.html&lt;/a&gt;#PostgreSQL #Window functions&lt;/p&gt;</description>
    </item>
    <item>
      <title>[PostgreSQL] 제약조건 (Constraint) 개념 및 설정 (Primary Keys, Foreign Keys, Unique, Not null, Check)</title>
      <link>http://localhost:1313/posts/21/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/21/</guid>
      <description>&lt;p&gt;데이터베이스는 데이터 타입 외에 제약조건들을 통해 데이터의 무결성을 유지한다.제약조건에는 여러 가지 종류가 있으며 DMBS에 마다 다양하지만, 이번 포스트는 PostgreSQL의 5가지 제약 조건들을 설명하겠다.1. &lt;a href=&#34;#scrollPk&#34;&gt;Primary Keys(PK)&lt;/a&gt;2. &lt;a href=&#34;#scrollFk&#34;&gt;Foreign Keys(FK)&lt;/a&gt;3. &lt;a href=&#34;#scrollCheck&#34;&gt;Check&lt;/a&gt;4. &lt;a href=&#34;#scrollNotNull&#34;&gt;Not-null&lt;/a&gt;5. &lt;a href=&#34;#scrollUnique&#34;&gt;Unique&lt;/a&gt;## 1. Primary Keys (PK)- Primary Keys는 테이블의 각 ROW를 구분하는 유니크한 컬럼 혹은 컬럼의 조합이다.- Not- null, Unique Constraints의 조합이다. 테이블인 단 1개의 PK만 가질 수 있다.- PK 생성 시 Postgresql은 B-tree 인덱스를 자동으로 부여한다.- B-tree 인덱스를 사용하기 때문에 컬럼의 조합으로 PK를 설정 시 순서가 중요하다. (상세 내용은 다음 포스트에서 확인이 가능하다.)&lt;a href=&#34;https://junhkang.tistory.com/6&#34;&gt;2023.09.12 - [Postgresql] - [PostgreSQL] B-tree 인덱스의 원리 및 특징&lt;/a&gt;[PostgreSQL] B-tree 인덱스의 원리 및 특징PostgreSQL에는 6가지의 인덱스 종류가 있다. 각각의 인덱스는 다양한 데이터 탐색을 위해 다른 알고리즘을 사용한다. 그중 가장 일반적으로 사용되고, 가장 먼저 도입된 알고리즘인 B-tree 인덱스에junhkang.tistory.com###           1-1. 테이블 생성 시 PK 부여&lt;code&gt;-- 단일 설정CREATE TABLE po_headers (po_no INTEGER PRIMARY KEY,vendor_no INTEGER,description TEXT,shipping_address TEXT);-- 복합설정CREATE TABLE TABLE (column_1 data_type,column_2 data_type,&amp;amp;hellip;PRIMARY KEY (column_1, column_2));&lt;/code&gt;###           1-2. 기존 테이블에 PK 속성 부여&lt;code&gt;ALTER TABLE table_name ADD PRIMARY KEY (column_1, column_2);-- 자동 증가하는 PK 설정ALTER TABLE vendors ADD COLUMN ID SERIAL PRIMARY KEY;&lt;/code&gt;###           1-3. PK 삭제&lt;code&gt;ALTER TABLE table_name DROP CONSTRAINT primary_key_constraint;&lt;/code&gt;## 2. Foreign Keys&amp;gt; 외래키(Foreign Keys)는 다른 테이블의 Primary Key에 참조된 컬럼 혹은 컬럼의 조합이다.다른 테이블과의 관계에 따라 다양한 FK를 가질 수 있다. 외래키 설정 후 parent 컬럼의 상태에 따라 다음 액션을 지정할 수 있다.a. SET NULLb. SET DEFAULTc. RESTRICTd. NO ACTIONe. CASCADEPostgresql에서는 다음 5가지 parent데이터 변경에 대한 옵션을 제공한다. 다음 FK 설정 예제는 parent데이터가 삭제될 경우 종속된 데이터를 null로 업데이트한다. Cascade의 경우 parent 데이터가 삭제될 경우 종속된 데이터들도 같이 전체 삭제된다.###           2-1. FK 생성&lt;code&gt;CREATE TABLE customers(customer_id INT GENERATED ALWAYS AS IDENTITY,customer_name VARCHAR(255) NOT NULL,PRIMARY KEY(customer_id));CREATE TABLE contacts(contact_id INT GENERATED ALWAYS AS IDENTITY,customer_id INT,contact_name VARCHAR(255) NOT NULL,phone VARCHAR(15),email VARCHAR(100),PRIMARY KEY(contact_id),CONSTRAINT fk_customerFOREIGN KEY(customer_id)REFERENCES customers(customer_id)-- 다음 설정은 parent 데이터가 삭제될시 참조데이터를 null로 업데이트한다.ON DELETE SET NULL);&lt;/code&gt;## 3. CheckBoolean 타입으로 컬럼에 제약을 줘서 insert 혹은 update 전에 테이블에 유효한 데이터인지를 검증한다.(맞지 않는다면 Constraint violation error를 발생시킨다.)###           3-1. Check Constraint 부여한 채로 테이블 생성&lt;code&gt;CREATE TABLE employees (id SERIAL PRIMARY KEY,first_name VARCHAR (50),last_name VARCHAR (50),birth_date DATE CHECK (birth_date &amp;gt; &#39;1900-01-01&#39;),joined_date DATE CHECK (joined_date &amp;gt; birth_date),salary numeric CHECK(salary &amp;gt; 0));&lt;/code&gt;다음 테이블에는 2가지 Constraint이 걸려있다. birth_date는 1900-01-01 이후 날짜여야 하며, joined_date는 birth_date 이후 날짜여야만 한다.###           3-2. 기존에 테이블에 Check Constraint 추가&lt;code&gt;ALTER TABLE prices_listADD CONSTRAINT price_discount_checkCHECK (price &amp;gt; 0AND discount &amp;gt;= 0AND price &amp;gt; discount);&lt;/code&gt;## 4. Not null특정 컬럼에 Null 제약을 줘서 insert 혹은 update시 해당 값이 null이 아닌지를 검증한다.###           4-1. Not null Constraint 부여&lt;code&gt;CREATE TABLE table_name(...column_name data_type NOT NULL,...);&lt;/code&gt;check와 Not null을 동시에 적용 가능하다.&lt;code&gt;CREATE TABLE invoices(id SERIAL PRIMARY KEY,product_id INT NOT NULL,qty numeric NOT NULL CHECK(qty &amp;gt; 0),net_price numeric CHECK(net_price &amp;gt; 0));&lt;/code&gt;###           4-2. 기존 테이블에 not null 속성을 추가해당 컬럼에 null 값이 없어야 적용 가능하다.&lt;code&gt;ALTER TABLE table_nameALTER COLUMN column_name SET NOT NULL;-- 여러개ALTER TABLE table_nameALTER COLUMN column_name_1 SET NOT NULL,ALTER COLUMN column_name_2 SET NOT NULL,...;&lt;/code&gt;종종 두 컬럼 중 적어도 1개는 null이 아니게 설정해야 할 경우가 있다.&lt;code&gt;CREATE TABLE users (id serial PRIMARY KEY,username VARCHAR (50),password VARCHAR (50),email VARCHAR (50),CONSTRAINT username_email_notnull CHECK (NOT (( username IS NULL  OR  username = &#39;&#39; )AND( email IS NULL  OR  email = &#39;&#39; ))));&lt;/code&gt;## 5. Uniqueinsert 혹은 update 시 해당 컬럼에 유니크한 값이 들어있는지를 확인한다. 단일 컬럼 혹은 컬럼의 조합으로 설정이 가능하며 Unique index가 자동으로 부여된다.###           5-1. Unique Constraint 적용한 테이블 생성&lt;code&gt;CREATE TABLE person (id SERIAL PRIMARY KEY,first_name VARCHAR (50),last_name VARCHAR (50),email VARCHAR (50) UNIQUE);&lt;/code&gt;컬럼의 조합에 설정하고 싶을 때는&lt;code&gt;CREATE TABLE table (c1 data_type,c2 data_type,c3 data_type,UNIQUE (c2, c3));&lt;/code&gt;###           5-2. 기존 테이블에 Unique Constraint 추가&lt;code&gt;CREATE UNIQUE INDEX CONCURRENTLY equipment_equip_idON equipment (equip_id);ALTER TABLE equipmentADD CONSTRAINT unique_equip_idUNIQUE USING INDEX equipment_equip_id;&lt;/code&gt;참고&lt;a href=&#34;https://www.postgresqltutorial.com/postgresql-tutorial/postgresql-unique-constraint/&#34;&gt;https://www.postgresqltutorial.com/postgresql-tutorial/postgresql-unique-constraint/&lt;/a&gt;&lt;a href=&#34;https://www.postgresqltutorial.com/postgresql-tutorial/postgresql-check-constraint/&#34;&gt;https://www.postgresqltutorial.com/postgresql-tutorial/postgresql-check-constraint/&lt;/a&gt;#CHECK #constraint #PostgreSQL #unique #not null #Primary Keys #Foreign Keys&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Spring] Spring Security6 filterchain 사용시 jsp 뷰 렌더링 설정</title>
      <link>http://localhost:1313/posts/51/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/51/</guid>
      <description>&lt;p&gt;스프링부트 3.&lt;em&gt;.&lt;/em&gt; 버전 업을 하며 Spring Security6으로 업데이트 중이다.더 이상 지원하지 않는 WebSecurityConfigurerAdapter를 SecurityFilterChain으로 변경 시 포워딩되는 jsp 파일 경로가 필터에 걸려 노출되지 않는 현상이 발생하였다.### 1-1. 기존 샘플 소스&lt;code&gt;@Configurationpublic class SecurityConfig  {@Beanpublic SecurityFilterChain config(HttpSecurity http) throws Exception {http.authorizeHttpRequests((auth) -&amp;gt; auth.requestMatchers(&amp;quot;/&amp;quot;).permitAll().anyRequest().authenticated());}&lt;/code&gt;기존과 같이 &amp;ldquo;/&amp;rdquo; 경로에 대한 권한을 부여하였지만, jsp 경로에 대한 권한부족으로 페이지 접근에 실패하였다.## 2. 원인&amp;gt; Spring Security 5.8 and earlier only &lt;a href=&#34;https://docs.spring.io/spring-security/reference/5.8/servlet/authorization/architecture.html&#34;&gt;perform authorization&lt;/a&gt; once per request. This means that dispatcher types like FORWARD and INCLUDE that run after REQUEST are not secured by default.Spring Security6 에서 페이지 전환 시 forwards, includes의 타입의 요청이 security filter에 기본적으로 포함되게 변경되었다.## 3. 해결### 3-1. forwards/includes 타입 요청을 허용하도록 수정 (스프링 공식문서 참고)&lt;code&gt;@Configurationpublic class SecurityConfig  {@Beanpublic SecurityFilterChain config(HttpSecurity http) throws Exception {http.authorizeHttpRequests((auth) -&amp;gt; auth.requestMatchers(&amp;quot;/&amp;quot;).permitAll().dispatcherTypeMatchers(DispatcherType.FORWARD).permitAll().dispatcherTypeMatchers(DispatcherType.INCLUDE).permitAll().anyRequest().authenticated());}&lt;/code&gt;### 3-2. jsp 파일 경로 (ex. /WEB-INF/view/*)를 허용하도록 수정&lt;code&gt; @Beanpublic SecurityFilterChain config(HttpSecurity http) throws Exception {http.authorizeHttpRequests((auth) -&amp;gt; auth.requestMatchers(&amp;quot;/&amp;quot;, &amp;quot;/WEB-INF/view/**&amp;quot;).permitAll().anyRequest().authenticated());return http.build();}&lt;/code&gt;참고&lt;a href=&#34;https://docs.spring.io/spring-security/reference/5.8/migration/servlet/authorization.html#_permit_forward_when_using_spring_mvc&#34;&gt;https://docs.spring.io/spring-security/reference/5.8/migration/servlet/authorization.html#_permit_forward_when_using_spring_mvc&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Spring] 단위 테스트, JUnit의 개념 및 단위 테스트 코드 작성 방법</title>
      <link>http://localhost:1313/posts/45/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/45/</guid>
      <description>&lt;p&gt;하나의 모듈을 기준으로 독립적으로 진행되는 가장 작은 단위의 테스트이다. 통합 테스트의 경우 시스템을 구성하는 컴포넌트들이 커질수록 테스트 시간이 길어지지만, 단위 테스트의 경우 해당 부분만 독립적으로 테스트하기에 코드의 변경이 있어도 빠르게 문제 여부를 확인할 수 있다. CleanCode 책에 의하면 깨끗한 테스트 코드는 다음 5가지 규칙을 따라야 한다.&amp;gt; Fast - 빠르게 동작하여 자주 돌릴 수 있어야 한다.Independent - 테스트는 독립적이며 서로 의존해서는 안된다.Repeatable -  어느 환경에서도 반복이 가능해야 한다.Self-validating - 테스트는 성공 또는 실패로 결과를 내어 자체 검증되어야 한다.Timely - 테스트는 적시에, 테스트하려는 실제코드를 구현하기 직전에 구현해야 한다.## 2. JunitJunit은 단위 테스트를 지원하는 오픈소스 프레임워크로 다음과 같은 특징을 가진다.- 문자 혹은 GUI 기반으로 실행- @Test 메서드를 호출할 때마다 새 인스턴스 생성- 예상결과를 검증하는 assertion 제공- 자동실행, 자체결과 확인 및 즉각적인 피드백 제공- 테스트 방식을 구분할 수 있는 어노테이션을 제공하며, 어노테이션만으로 간결하게 실행이 가능### ▶ 2-1. 어노테이션 종류&amp;gt; @DisplayName - 테스트 이름 명시@Test - 테스트를 수행할 메서드, Junit은 각 테스트끼리 영향을 주지 않도록 테스트 실행 객체를 매 테스트마다 만들고 종료 시 삭제@BeforeAll - 전체 테스트를 시작하기 전에 1회 실행 (ex. 데이터베이스 연결, 테스트환경 초기화, 전체 테스트 실행주기에 한 번만 호출)@BeforeEach - 테스트 케이스를 시작하기 전마다 실행 (테스트 메서드에 사용하는 객체 초기화, 테스트에 필요한 데이터 삽입 등)@AfterAll - 전체 테스트를 마치고 종료하기 전에 1회 실행 (데이터베이스 연결 종료, 공통으로 사용하는 자원 해제 등)@AfterEach - 테스트 케이스를 종료하기 전마다 실행 (테스트 이후 특정데이터를 삭제 등)### ▶ 2-2. AssertJJunit과 사용해 가독성을 높여주는 라이브러리로 다양한 문법을 지원한다. 기존 Junit은 기댓값과 실제 비교대상이 확실히 보이지 않아 잘 구분이 안되지만 isEqualTo 등 명확한 의미의 매머드로 대체가 가능하다.### ▶ 2-3. given-when-then 패턴요즘 단위테스트의 가장 보편적인 형태로 1개의 단위테스트를 3단계로 나눠서 처리하는 패턴이다.- given = 테스트 실행을 준비하는 단계 (어떤 상황, 데이터가 주어졌을 때)- when = 테스트를 진행하는 단계 (어떤 함수를 실행시키면 )- then = 테스트 결과를 검증하는 단계 (어떤 결과가 기대된다.)## 3. 단위 테스트 예제점수의 평균을 계산해주는 클래스에 대한 단위 테스트를 해보자. 해당 예제는 객체 간의 메시지 교환이 없는 단순한 값 비교, 예외 확인을 위한 테스트 케이스이다.(일반적으로 스프링 애플리케이션은 다양한 객체에서 메시지를 전달받아 의존성이 생기는데, 이럴 경우 Mock(가짜) 객체를 사용하여 테스트가 가능하다.)### ▶ 3-0. 테스트 대상인 평균점수 조회다음과 같이 0점 이상의 점수들에 대한 평균을 구하는 클래스가 있을 때&lt;code&gt;public class AverageScoreCalculator {private static Integer sum = 0;private static Integer count = 0;public void addScore(Integer score) {if (!validateScores(score))	{throw new IllegalStateException(&amp;quot;Invalid score&amp;quot;);}sum += score;count++;}private boolean validateScores(Integer score) {return score &amp;gt; 0;}public Double getAverageScore() {return (double) (sum / count);}}&lt;/code&gt;### ▶ 3-1. 점수의 평균이 일치하는지 테스트실제 평균의 값과, 클래스 연산 결과가 일치하는지 테스트한다.&lt;code&gt;@DisplayName(&amp;quot;점수의 평균 테스트&amp;quot;)@Testvoid averageScoreTest() {//givenAverageScoreCalculator averageScoreCalculator = new AverageScoreCalculator();int[] scores = {10,20,30,40,50};//whenfor (int i = 0; i&amp;lt;scores.length; i++)	{averageScoreCalculator.addScore(scores[i]);}Double averageScore = averageScoreCalculator.getAverageScore();//thenassertThat(averageScore).isEqualTo(Arrays.stream(scores).average().getAsDouble());}&lt;/code&gt;### ▶ 3-2. 평균점수의 범위 테스트점수의 평균이 1~100점 이내에 존재하는지 확인한다.&lt;code&gt;@DisplayName(&amp;quot;평균 점수 범위 테스트&amp;quot;)@Testvoid averageScoreRangeTest()	{//givenAverageScoreCalculator averageScoreCalculator = new AverageScoreCalculator();int[] scores = {10,20,30,40,50};//whenfor (int i = 0; i&amp;lt;scores.length; i++)	{averageScoreCalculator.addScore(scores[i]);}Double averageScore = averageScoreCalculator.getAverageScore();//thenassertThat(averageScore &amp;gt;= 0 &amp;amp;&amp;amp; averageScore &amp;lt;= 100).isTrue();}&lt;/code&gt;### ▶ 3-3. 개별점수 유효성 테스트유효하지 않은 점수가 인풋 될 경우 IllegalStateException이 기대되기에, assertThrow로 Exception을 테스트한다.&lt;code&gt;@DisplayName(&amp;quot;개별 잘못된 점수 테스트&amp;quot;)@Testpublic void averageScoreInvalidScoreTest(){//givenAverageScoreCalculator averageScoreCalculator = new AverageScoreCalculator();int[] scores = {10,20,30,40,-1};//whenfinal IllegalStateException exception = assertThrows(IllegalStateException.class, () -&amp;gt; {for (int i = 0; i&amp;lt;scores.length; i++)	{averageScoreCalculator.addScore(scores[i]);}});//thenassertThat(exception.getMessage()).isEqualTo(&amp;quot;Invalid score&amp;quot;);}&lt;/code&gt;## 4. 주요 Assert 메서드### ▶ 4-1. 주요 비교 검증 테스트 메서드메서드 이름설명isEqualTo(A)A 값과 같은지 검증isNotEqualTo(A)A 값과 다른지 검증contains(A)A 값을 포함하는지 검증doesNotContain(A)A 값을 포함하지 않는지 검증startWith(A)접두사가 A인지 검증endsWith(A)접미사가 A인지 검증isEmpty()비어 있는 값인지 검증isNotEmpty()비어 있지 않은 값인지 검증isPositive()양수인지 검증isNegative()음수인지 검증isGreaterThan(a)a보다 큰 값인지 검증isLessThan(a)a보다 작은 값인지 검증### ▶ 4-2. HTTP 주요 응답코드 테스트 메서드코드매핑 메서드설명200 OKisOk()HTTP 응답코드가 200 OK인지 검증201 CreatedisCreated()HTTP 응답코드가 201 Created 검증400 Bad RequestisBadRequest()HTTP 응답코드가 400 BadRequest검증403 ForbiddenisForbidden()HTTP 응답코드가 403 Forbidden검증404 Not FoundisNotFound()HTTP 응답코드가 404 Not Found 검증4&lt;strong&gt;is4xxClientError()HTTP 응답코드가 4&lt;/strong&gt; 검증500 Internal Server ErrorisInternalServerError()HTTP 응답코드가 500 InternalServerError 검증5&lt;strong&gt;is5xxClientError()HTTP 응답코드가 5&lt;/strong&gt; 검증참고도서 : 스프링 부트 3 백엔드 개발자 되기 - 자바 편&lt;a href=&#34;https://mangkyu.tistory.com/143&#34;&gt;https://mangkyu.tistory.com/143&lt;/a&gt;#spring #TDD #JUnit #단위테스트 #assertj&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Spring] 순환참조란? The dependencies of some of the beans in the application context form a cycle</title>
      <link>http://localhost:1313/posts/47/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/47/</guid>
      <description>&lt;p&gt;순환참조는 맞물린 의존성 주입 (DI) 상태에서 어떤 빈을 먼저 생성할지 결정하지 못해서 생기에 발생한다. BeanA에서 BeanB를 참조(BeanA-&amp;gt;BeanB) 일 경우 스프링은 BeanB를 먼저 생성 후 BeanA를 생성하기에, BeanB에서 다시 BeanA를 참조할 경우 (BeanA-&amp;gt;BeanB-&amp;gt;BeanA) 순환 참조가 발생하게된다.## 2. 의존성 주입의존성 주입의 3가지 상황 (생성자 주입방식, 필드 주입방식, Setter주입)에서 순환참조가 발생할수 있다. 다음 포스트 각각의 상세 내용을 확인할 수 있고, 이번 포스트에서는 각각의 경우에 순환참조가 발생하면 어떤 차이점이 있는지 확인해 보자.&lt;a href=&#34;https://junhkang.tistory.com/42&#34;&gt;2023.11.06 - [Spring] - [Spring] IoC(제어의 역전) &amp;amp; DI(의존성 주입)의 개념&lt;/a&gt;[Spring] IoC(제어의 역전) &amp;amp; DI(의존성 주입)의 개념1. IoC (Inversion of Control) 제어의 역전 IoC란 메인 프로그램에서 컨테이너나 프레임워크로 객체와 객체의 의존성에 대한 제어를 넘기는 것을 말한다. 프레임워크 없이 개발할 때는 각 객체에 대한junhkang.tistory.com### ▶ 2-1. 생성자 주입&lt;code&gt;@Componentpublic class BeanA {private BeanB beanB;public void BeanA(BeanB beanB){this.beanB = beanB;}}@Componentpublic class BeanB {private BeanA beanA;public void BeanB(BeanA beanA){this.beanA = beanA;}}&lt;/code&gt;생성자 주입의 경우, 애플리케이션 구동 시 스프링 컨테이너(IOC)는 BeanA 빈을 생성하기 위해 BeanB를 찾고 BeanB를 찾기 위해 Bean A를 찾기 때문에 순환참조가 발생하게 된다.### ▶ 2-2. 필드 주입, Setter 방식필드 주입, Setter 방식은 애플리케이션의 실행 시점에서는 에러가 발생되지 않는다. 어플리케이션의 실행 시점이 아닌, 실제로 사용되는 시점에 실행되는 메서드가 순환 호출되기 때문이다. 필요 없는 시점에는 null 상태로 유지 후 사용될 때 의존성이 주입되며 참조되기 시작한다.## 3. 해결책### ▶ 3-1. @Lazy 어노테이션&lt;code&gt;@Componentpublic class BeanA {private BeanB beanB;public void BeanA(BeanB beanB){this.beanB = beanB;}}@Componentpublic class BeanB {private BeanA beanA;public void BeanB(@Lazy BeanA beanA){this.beanA = beanA;}}&lt;/code&gt;다음과 같이 @Lazy 어노테이션을 통해 시점을 지연시킬 수 있으나 스프링에서는 이 방식을 추천하지 않는다. 애플리케이션 로딩시점이 아닌 Bean이 필요한 시점에 주입받기 때문에 특정 HTTP 요청을 받을 때 Heap 메모리가 증가할 수 있으며 메모리가 충분하지 않은 경우 장애로 이어질 수 있다. 또한 잘못된 빈의 생성시점을 늦추기에 문제상황에 대한 인식이 늦어질 수 있다.### ▶ 3-2. 설계 변경근본적으로 순환참조가 일어나지 않는 설계를 해야 한다.단순하게는 BeanA -&amp;gt; BeanB-&amp;gt; BeanA의 관계를 BeanA -&amp;gt; BeanB -&amp;gt; BeanC 형태로 참조가 순환되지 않도록 분리해야 한다.#spring #의존성주입 #순환참조&lt;/p&gt;</description>
    </item>
    <item>
      <title>[WEB] SSR(Server Side Rendering) 과 CSR(Client Side Rendering)의 개념 및 차이</title>
      <link>http://localhost:1313/posts/49/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/49/</guid>
      <description>&lt;p&gt;서버에서 렌더링 준비를 마친 상태로 클라이언트에 자원을 전달한다.### 1-1. SSR 작동 방식&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/images/posts/49/img.png&#34;&gt;- 유저가 웹사이트 자원을 요청- 서버에서 &amp;ldquo;렌더링 가능한&amp;rdquo; HTML 파일 생성 (리소스 체크, 컴파일 후 완성된 HTML 콘텐츠 생성)- 브라우저는 즉시 HTML 렌더링, 사이트 조작 불가 상태- 클라이언트가 자바스크립트를 다운받는다.- 다운로드하여지고 있는 사이 콘텐츠는 볼 수 있지만 조작은 불가, 이 기간 동안 유저의 액션을 기억- 브라우저가 자바스크립트 프레임워크를 실행- 자바스크립트가 컴파일된 후 기억하고 있던 유저 액션을 실행시킨다.- 서버에서 렌더링 가능한 상태로 이미 전달되기에 자바스크립트를 받는 동안 특정 자원을 볼 수 있다.### 1-2. SSR 장점- 초기 페이지의 로딩속도가 빠르다.- 서버에서 컴파일되어 클라이언트로 넘어오기에 클롤러 대응에 용이하여 SEO 친화적이다.- 클라이언트 하드웨어 및 소프트웨어 성능에 영향을 덜 받는다.### 1-3. SSR 선택 기준- 네트워크가 느릴 때 (페이지마다 나눠서 불러오기 때문)- 검색엔진 최적화가 필요할 때- 최초 로딩이 빨라야 할 때- 메인 스크립트가 크고 로딩이 느릴 때- 웹사이트 상호작용이 별로 없을 때## 2. CSR (Client Side Rendering)렌더링이 클라이언트에서 일어난다. 서버에선 HTML과 JS를 보내고, 클라이언트에서 렌더링을 시작한다. 모든 로직, 데이터, 템플릿, 라우팅은 클라이언트에서 실행된다. 자바스크립트 번들 크기의 영향을 많이 받기에 코드 분할을 고려해야 하며, 적시 적소에 필요한 기능만을 제공해야 한다.### 2-1. CSR 작동방식&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/images/posts/49/img_1.png&#34;&gt;- 유저가 웹사이트 자원을 요청- CDN이 자바스크립트 링크가 포함된 HTML 파일을 바로 보낸다.- 브라우저는 HTML을 다운로드하고 자바스크립트를 다운로드한다. 그동안 사이트는 유저에게 보이지 않는다.- 자바스크립트가 실행된다. API로부터 받은 데이터를 위치에 넣어준다. 이제 페이지는 상호작용이 가능하다.- 서버에서 처리 없이 클라이언트로 보내주기 때문에 자바스크립트, HTML이 모두 다운되고 실행되기 전에 유저가 볼 수 있는 내용은 없다.### 2-2. CSR 장점- 이미 모든 스크립트가 사전에 로딩되었기에, 후속 페이지 로드 시간이 빠르다.- 서버를 호출할 때마다 전체 UI를 다시 로딩할 필요 없다.- 클라이언트 자원을 사용하기에 서버 부하가 적다.### 2-3. CSR 선택기준- 네트워크가 빠르고, 서버 성능이 좋지 않을 때- 사용자에게 보여줄 데이터가 많을 때- 메인 스크립트가 가벼울 때- 웹 애플리케이션에 사용자와 상호작용할 것들이 많을 때참고&lt;a href=&#34;https://ajdkfl6445.gitbook.io/study/web/csr-vs-ssr-vs-ssg&#34;&gt;https://ajdkfl6445.gitbook.io/study/web/csr-vs-ssr-vs-ssg&lt;/a&gt;&lt;a href=&#34;https://off-dngw.github.io/posts/SSR-CSR/&#34;&gt;https://off-dngw.github.io/posts/SSR-CSR/&lt;/a&gt;#csr #SSR&lt;/p&gt;</description>
    </item>
    <item>
      <title>[디자인패턴] 추상 팩터리(Abstract Factory) 패턴의 개념, 예제, 장단점, 활용</title>
      <link>http://localhost:1313/posts/61/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/61/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;추상 - 구체적으로 어떻게 구현되는지 생각하지 않고 인터페이스(API)에만 주목하는 상태공장 - 부품을 조립하여 제품 완성추상 + 공장 패턴 : 추상적인 공장에서 추상적인 부품을 조합하여 추상적인 제품을 만든다. 부품의 구체적인 구현에 집중하지 않고 인터페이스에 주목, 인터페이스만 사용하여 부품을 조립하고 제품으로 완성한다.다음 표를 보면 추상 팩토리가 어떤 구조로 이루어졌는지 확인할 수 있다.&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/images/posts/61/img.png&#34;&gt;- Abstract Factory : 최상위 공장, 메서드들을 추상화한다. AbstractProduct의 인스턴스를 만들기 위한 인터페이스를 결정한다.- Concrete Factory : 서브 공장 클래스, 유형에 맞는 객체를 반환하도록 메서드들을 재정의한다. AbstractFactory의 인터페이스를 구현한다.- Abstract Product : 타입의 제품을 추상화한 인터페이스이다. AbstractFactory에 의해 만들어지는 추상적인 부품이나 제품의 인터페이스(API)를 결정한다.- ConcreteProduct : 각 유형의 구현체, 팩토리 객체로부터 생성한다. AbstractProduct의 인터페이스를 구현한다.## 2. 예제사용할 예제는 계층 구조로 된 링크 페이지를 HTML파일로 바꾸는 코드이다. (&amp;ldquo;JAVA 언어로 배우는 디자인 패턴 입문 3편&amp;quot;의 예제 활용) HTML 계층 구조를 추상 팩토리 패턴을 통해 구현한 것으로 2개의 패키지로 분리된 클래스군으로 구성되어 있다.- factory : 추상적인 공장, 부품, 제품을 포함하는 패키지- listFactory : 구체적인 공장, 부품, 제품을 포함하는 패키지factory 하위의 추상 공장/부품과 listFactory 하위의 구체적인 부품/공장을 통해 html list를 구현한다.### 2-1. 추상적인 부품 - Item, Link, TrayHTML 요소들을 다룰 추상적인 부품들을 정의한다. Link와 Tray를 통일적으로 다루기 위한 Item 클래스를 생성한다. HTML 문자열을 반환하는 makeHTML()은 추상메서드로 선언하여 하위 클래스에서 상황에 맞게 구현할 수 있게 한다.#### 2-1-1. Item&lt;code&gt;public abstract class Item {protected String caption;public Item(String caption) {this.caption = caption;}public abstract String makeHTML();}&lt;/code&gt;#### 2-1-2. Link&lt;code&gt;public abstract class Link extends Item {protected String url;public Link(String caption, String url) {super(caption);this.url = url;}}&lt;/code&gt;#### 2-1-3. Tray&lt;code&gt;public abstract class Tray extends Item {protected List tray = new ArrayList&amp;lt;&amp;gt;();public Tray(String caption) {super(caption);}public void add(Item item) {tray.add(item);}}&lt;/code&gt;### 2-2. 추상적인 공장 - Factoryclass명을 통해 구체적인 공장의 인스턴스를 생성한다. getFactory를 통해 구체적인 공장 인스턴스를 생성하지만, 리턴값은 추상적인 공장(Factory) 임을 주의하자. 추상 부품들을 반환하는 createLink, createTray, createPage 같은 추상 메서드들은 메서드 이름과 시그니처만 여기서 확실히 정의하고, 제품의 구제적인 생성 및 부품 선정은 하위 클래스에게 일임한다.&lt;code&gt;public abstract class Factory {public static Factory getFactory(String classname) {Factory factory = null;try {factory = (Factory)Class.forName(classname).getDeclaredConstructor().newInstance();} catch (ClassNotFoundException e) {System.out.println(classname + &amp;quot; 클래스가 발견되지 않았습니다.&amp;quot;);} catch (Exception e) {e.printStackTrace();}return factory;}public abstract Link createLink(String caption, String url);public abstract Tray createTray(String caption);public abstract Page createPage(String title, String author);}&lt;/code&gt;### 2-3. 구체적인 공장 - ListFactoryFactory 클래스의 createLink, createTray, createPage 추상 메스드들을 구체적으로 정의한다.&lt;code&gt;public class ListFactory extends Factory {@Overridepublic Link createLink(String caption, String url) {return new ListLink(caption, url);}@Overridepublic Tray createTray(String caption) {return new ListTray(caption);}@Overridepublic Page createPage(String title, String author) {return new ListPage(title, author);}}&lt;/code&gt;### 2-4. 구체적인 부품 - ListLink, ListTray상위 클래스의 makeHTML 추상 메서드를 구현한다. 각 클래스의 요청에 맞는 HTML을 파싱 하여 String 형태로 리턴한다.#### 2-4-1. ListLink&lt;code&gt;public class ListLink extends Link {public ListLink(String caption, String url) {super(caption, url);}@Overridepublic String makeHTML() {return &amp;quot;  &amp;quot; + caption + &amp;quot;\n&amp;quot;;}}&lt;/code&gt;#### 2-4-2. ListTray####&lt;code&gt;public class ListTray extends Tray {public ListTray(String caption) {super(caption);}@Overridepublic String makeHTML() {StringBuilder sb = new StringBuilder();sb.append(&amp;quot;\n&amp;quot;);sb.append(caption);sb.append(&amp;quot;\n\n&amp;quot;);for (Item item: tray) {sb.append(item.makeHTML());}sb.append(&amp;quot;\n&amp;quot;);sb.append(&amp;quot;\n&amp;quot;);return sb.toString();}}&lt;/code&gt;## 3. Abstract Factory 패턴의 장단점Abstract Factory 패턴에 Concrete Factory(구체적인 공장)을 추가하는 것은 간단하다. 어떤 클래스를 만들고 어떤 메서드를 구현해야 하는지가 명확하기 때문이다. 예제에서 ListFactory 외에 다른 Factory를 생성하려 한다면, Factory, Link, Tra 하위 클래스를 생성하고 각각 추상 메서드를 다시 구현하면 된다. 이 과정에서 Abstract Factory(추상 공장)에는 어떠한 수정도 가해지지 않는다. 여기서 오는 장점으로는- 객체 생성코드의 확장성 보장- 객체 간의 결합도 낮춤- 구현체 클래스에 대한 의존성 감소하지만 공장을 추가하는 게 아닌 부품을 추가해야 한다면 어떨까? Factory 추상 팩토리에 Picture라는 부품을 추가해야 한다면, 이미 구현된 Concrete Factory 전체를 Picture에 대응하도록 수정해야 한다. 현재 예제에서는 createPicture라는 메서드를 모든 구체적인 공장에 추가해 주어야 한다. 이미 만들어진 공장이 많을수록 더 큰 작업이 될 것이다. 여기서 오는 단점으로는- 복잡한 구조- 유연성이 저하- 추가적인 클래스 생성 필요## 4. 결론 / 활용같은 유형의 다양한 제품, 부품을 생성할 때 굉장히 효율적인 패턴이다. 수정에는 닫혀있고 확장에는 열려있는 패턴으로 객체 간의 결합도를 낮춰주지만 추가적인 클래스 생성으로 유연성이 떨어지고 복잡한 구조가 될 우려가 있다. 확장 방향성에 대한 충분한 검토가 끝난 후 적용해야 효율을 볼 수 있다.- 참고 : JAVA 언어로 배우는 디자인 패턴 입문 3편- 상세 예제소스는 깃허브에서 확인가능&lt;a href=&#34;https://github.com/junhkang/java-design-pattern/tree/master/src/main/java/com/example/javadesignpattern/abstractFactory&#34;&gt;https://github.com/junhkang/java-design-pattern/tree/master/src/main/java/com/example/javadesignpattern/abstractFactory&lt;/a&gt;#디자인 패턴 #Abstract Factory #추상 팩토리&lt;/p&gt;</description>
    </item>
    <item>
      <title>[운영체제(OS)] 스레드 (Thread), 멀티스레드(Multithreaded Programming)란?</title>
      <link>http://localhost:1313/posts/28/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/28/</guid>
      <description>&lt;p&gt;CPU 수행의 기본단위이며 특히 프로세스 안의 흐름의 단위이다. 스레드가 수행되는 환경을 Task라고 하며 Thread ID, Program counter, register set, Stack space로 구성된다. 각각의 스레드는 레지스터 상태와 스택을 갖는다. Code, Data 섹션이나 운영체제 자원들은 스레드끼리 공유한다.### 스레드의 종류스레드는 지원 주체에 따라 2가지로 나눌 수 있다.User Threads- 유저 스레드는 사용자 수준의 스레드 라이브러리가 관리하는 스레드- 라이브러리는 스레드의 생성 및 스케쥴링 등 관리 기능을 제공한다.- 동일 메모리에서 스레드가 생성 및 관리되므로 속도가 빠르다.- 여러 개의 사용자 스레드 중 하나의 스레드가 시스템 호출 등으로 중단되면 나머지 스레드가 같이 종료된다. (커널이 프로세스 내부 스레드를 인식하지 못하여 해당 프로세스를 대기상태로 전환시키기 때문)- 스레드 라이브러리에는 POSIX, Pthreads, Win32 threads, Java threads 대표적이다Kernel Threads- 커널 스레드는 커널이 지원하는 스레드- 커널 스레드를 사용하면 안정적이지만 유저모드에서 커널모드로 계속 바꿔줘야 하기에 성능이 저하된다.- 반대로 유저 스레드를 사용하면 안정성은 떨어지지만 성능이 저하되지는 않는다.- 스레드가 시스템 호출 등으로 중단되어도 다른 스레드를 중단시키지 않고 계속 실행시킨다.### Thread Group (스레드 그룹)Thread Group (스레드 그룹)이란 관련 있는 스레드를 그룹으로 묶어 다루는 장치이다. 쓰레드 그룹은 다른 스레드그룹에 포함될 수 있으며, 트리형태로 연결된다. 스레드는는 자신이 포함된 스레드 그룹이나 하위 그룹에는 접근가능 하지만, 다른 그룹에는 접근할 수 없다.### Deamon Thread(데몬 스레드)- 다른 일반 스레드의 작업을 돕는 보조 쓰레드- 일반 스레드가 모두 종료되면 자동으로 종료- 일정시간마도 자동수행되는 저장/ 화면 갱신등에 사용### Thread Pools스레드를 요청할 때마다 매번 새로 생성하고, 수행하고, 지우고 반복하면 성능저하로 이어진다.그래서 미리 스레드 풀에 여러 개의 스레드를 만들어두고 요청이 오면 스레드풀에서 스레드를 할당해 주는 방법을 사용한다.## 2. 멀티스레드란?한 번에 하나의 작업만 수행하면 싱글 스레드, 하나의 프로세스가 둘 이상의 스레드가 동시에 작업을 수행하면 멀티스레드라 한다.멀티프로세싱 시스템이 여러 개의 완전한 처리 장치들을 포함하는 반면 멀티스레딩은 스레드 수준뿐 아니라 명령어 수준의 병렬 처리에까지 신경을 쓰면서 하나의 코어에 대한 이용성을 증가하는 것에 초점을 두고 있다.### 멀티스레드의 장점두 프로세스가 하나의 데이터를 공유하려면 공유메모리 또는 파이프를 사용해야 하지만, 효율이 떨어지고 구현/관리하기 힘들다.프로세스사이 콘텍스트 스위치가 지속적으로 일어나면 성능저하 발생 (스레드 전환 시에도 일어나지만 속도가 더 빠르다)응답성 : 대화형 프로그램을 멀티스레드화 하면 일부 스레드가 중단되거나 긴 작업을 수행하더라도  다른 스레드가 별도의 작업을 할 수 있어 응답성이 좋다.자원공유 : 프로세스 내의 자원과 메모리를 공유함으로 시스템 자원의 낭비가 적다. 또한 같은 주소 공간 내에 여러 개의 활동성 스레드를 가질 수 있다는 장점이 있다.경제성 : 메모리와 자원할당은 많인 비용이 소모된다. 스레드는 프로세스 내 자원을 공유하기에 스레드생성과 Context Switching을 하는 것이 효율적이다.멀티프로세서 활용 : 각각의 스레드가 다른 프로세스에서 병렬로 수행 가능하다. 단일 쓰레드 프로세스는 CPU가 많아도 1개의 CPU에서만 실행되지만, 다중 스레드화 하면 다중 CPU에서 병렬성이 증간된다.프로세스와 비교두 프로세스가 하나의 데이터를 공유하려면 공유메모리 또는 파이프를 사용해야 하지만, 효율이 떨어지고 구현/관리하기 힘들다.스레드, 프로세스 사이 콘텍스트 스위치가 지속적으로 일어나면 성능저하 발생하나 스레드의 Context Switching의 속도가 더 빨라서 효율적이다.### 멀티스레드의 단점- 캐시, 변환 생인 버퍼(TLB) 등의 하드웨어 리소스를 공유할 때 서로 간섭할 수 있다.- Context Switching 시간이 길수록 멀티 쓰레딩의 효율은 저하되어 단순 계산은 싱글 스레드 보다 실행시간이 개선되지 않고 오히려 지연될 수 있다.- 멀티 쓰레딩의 하드웨어 지원을 위해 애플리케이션, 운영체제 모두에 최적화 변경이 필요하다.- 각 스레드 중 어떤 것이 먼저 실행될지 그 순서를 알 수 없다.예를 들어 스레드 1, 스레드 2로 다음 작업을 수행할 때,&amp;gt; - 공유되는 변수 i의 값을 레지스터에 저장- 레지스터의 값을 1 증가- 변수 i에 그 값을 저장쓰레드동작i스레드 1의 레지스터스레드 2의 레지스터스레드 1i의 값을 레지스터에 저장00스레드 1레지스터 값을 1 증가01스레드 1i에 값 저장11스레드 2i의 값을 레지스터에 저장111스레드 2레지스터 값을 1 증가112스레드 2i에 값 저장212스레드 순서가 정상적으로 처리된다면 다음과 같이 최종적으로 i = 2가 되지만, 스레드 실행 순서가 달라진다면스레드동작i스레드 1의 레지스터스레드 2의 레지스터스레드 1i의 값을 레지스터에 저장00스레드 2i의 값을 레지스터에 저장000스레드 1레지스터 값을 1 증가010스레드 2레지스터 값을 1 증가011스레드 1i에 값 저장111스레드 2i에 값 저장111i = 1 이 되기에 의도와 다른 수행이 일어나며, 스레드의 실행조건에 따라 다른 결과를 나타내기에 원인 파악이 힘들다.이러한 문제를 경쟁조건이라고 하며 세마포어 같은 방법으로 공유데이터에 접근하는 스레드의 개수를 한 개 이하로 유지하여 해결할 수 있다.### Context Switching컴퓨터가 동시에 처리할 수 있는 작업 수는 CPU의 코어 수량과 같다. CPU 코어보다 많은 스레드가 동시에 실행되면 각 코어별로 정해진 시간만큼 번갈아가며 작업을 수행한다. 각 스레드가 서로 번갈아가며 교체될때 쓰레드간 현재까지의 작업상태나 다음 작업에 필요한 데이터를 저장하고 읽는 작업을 하는데 이를 Context Switching라고 한다. Context Switching 시간이 길수록 멀티 쓰레딩의 효율은 저하된다. 그래서 많은 양의 단순계산은 싱글 쓰레드로 처리하는 것이 효율적인 경우가 있기에 쓰레드 수가 많은 게 항상 고성능은 아니다.### Multithreaded Server Architecture서버와 클라이언트 사이에도 멀티 스레드를 구현한다. 클라이언트가 새로운 요청을 하면 서버는 스레드를 새로 생성해서 요청을 수행한다.  프로세스 보다 쓰레드를 생성하는 것이 더 빠르기 때문에 효율적이다.### Multicore Programming동시성(Concurrency)동시성은 싱글 프로세스에서 사용되는 방식으로 프로세서가 여러 개의 스레드를 번갈아가면 수행하며 동시에 실행되는 것처럼 보이게 한다.병렬성(Parallelism)병렬성은 멀티코어 방식에서 사용되는 방식으로 여러 개의 코어가 스레드를 동시에 수행한다.## 3. Multithreading Models유저 스레드와 커널 쓰레드 관계를 정의하는 방식이다.### Many-to-One Model- 하나의 커널 스레드에 여러 개의 유저 스레드 연결- 사용자 수준에서의 스레드 관리- 주로 커널 스레드를 지원하지 않는 시스템에서 사용- 한 번에 하나의 유저스레드만 커널에 접근가능- 멀티코어 시스템에서 병렬적인 수행이 불가능### One-to-One Model- 하나의 유저 스레드에 하나의 커널 스레드가 대응하는 모델- Many-to-One방식에서 시스템 호출 시 다른 스레드들이 중단되는 문제를 해결할 수 있어 동시성 향상- 멀티프로세서 시스템에서는 동시에 여러 개 쓰레드 수행 가능- 유저 스레드 증가분만큼 커널 스레드가 증가.- 커널 스레드를 생성하는 것은 오버헤드가 큰 작업이기에 성능저하 발생가능### Many-to-Many Model- 여러 유저스레드가 더 적거나 같은 수의 커널 스레드에 대응하는 모델- 운영체제에 충분한 수의 커널 스레드를 생성가능- 커널 스레드의 구체적 개수는 프로그램이나 작동기기에 따라 상이- 멀티프로세서 프로그램에서는 싱글프로세서 보다 더 많은 커널 스레드가 생성- 커널이 사용자 스레드와 커널 스레드의 매핑을 적절하게 조절### Two-level Model- Many-to-Many 모델과 유사- 특정 유저 스레드를 위한 커널 스레드를 따로 제공하는 모델- 점유율이 높아야 하는 유저 스레드를 더 빠르게 처리 가능참고&lt;a href=&#34;https://ko.wikipedia.org/wiki/%EC%8A%A4%EB%A0%88%EB%93%9C_(%EC%BB%B4%ED%93%A8%ED%8C%85)&#34;&gt;https://ko.wikipedia.org/wiki/스레드_(컴퓨팅)&lt;/a&gt;&lt;a href=&#34;https://rebro.kr/174&#34;&gt;https://rebro.kr/174&lt;/a&gt;&lt;a href=&#34;http://www.tcpschool.com/java/java_thread_multi&#34;&gt;http://www.tcpschool.com/java/java_thread_multi&lt;/a&gt;&lt;a href=&#34;https://ko.wikipedia.org/wiki/%EB%A9%80%ED%8B%B0%EC%8A%A4%EB%A0%88%EB%94%A9&#34;&gt;https://ko.wikipedia.org/wiki/%EB%A9%80%ED%8B%B0%EC%8A%A4%EB%A0%88%EB%94%A9&lt;/a&gt;#OS #운영체제 #스레드 #멀티스레드&lt;/p&gt;</description>
    </item>
    <item>
      <title>[이펙티브 자바] 1. 생성자 대신 정적 팩터리 메서드를 고려하라</title>
      <link>http://localhost:1313/posts/53/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/53/</guid>
      <description>&lt;p&gt;클라이언트가 클래스 인스턴스를 얻는 방법에는 전통적인 방법 중 하나는  public이다. 하지만 정적 팩터리 메서드(static factory method)도 꼭 알아두어야한다.## 1. 정적 팩터리 메서드란?그렇다면 정적 팩터리 메서드는 무엇일까? 간단히 말해 객체 생성의 역할을 하는 클래스 메서드로, static 메서드를 통해 인스턴스를 생성하는 것이다. 다음은 java의 기본 Boolean 클래스 내 정적 팩토리 메서드의 간단한 예시이다.![](/images/posts/53/스크린샷 2024-01-17 오후 5.02.29.png)이팩티브 자바에서는 정적 팩토리 메서드를 사용할 시의 5가지 장점과 2가지 단점에 대해 서술하고 있어 자세한 비교를 통해 하나하나 알아보려 한다.## 2. 정적 팩토리 메서드 (static factory method)의 장점#### 2-1. 이름을 가질 수 있다.인스턴스를 대표하는 생성자가 명확하거나, 반환될 객체에 대한 설명이 필요하지 않을 경우에는 크게 느껴지지 않는 차이일 수 있지만, 이름을 가질 수 있어 반환될 객체의 특징을 설명할 수 있다는 것은 굉장한 장점이다. 이펙티브 자바에서는 BigInteger와 BigInteger.probablePrime의 차이를 예로 들고 있다. 먼저 BigInteger(int, int, Random)의 예제를 보면![](/images/posts/53/스크린샷 2024-01-17 오후 5.09.35.png)설명을 읽어보면 &amp;ldquo;지정된 bitLength의 소수일 가능성이 있는 임의의 BigInteger를 생성한다.&amp;ldquo;는 것을 이해할 수 있지만, 그전에는 명확한 반환될 객체의 특성을 알 수 없다. 또한, 하나의 시그니처로는 생성자를 한 개만 만들 수 있기에 제약이 있다. 예를 들어 동일한 BigInteger(int, int, Random) 생성자는 다른 의미를 가질 수 없다. BigInteger(int, Random, int)와 같이 순서를 바꾸거나, 추가하는 식으로 피해 갈 수는 있지만, 당연히 좋지 않은 방식이다. (추가될 때마다 클래스 설명 문서를 확인해야 하고, 호출하는데 실수가 있을 수 있다.)그에 비해 자바 4에서 추가된 BigInteger.probablePrime을 보면![](/images/posts/53/스크린샷 2024-01-17 오후 5.16.10.png)&amp;ldquo;값이 소수인 BigInteger를 반환한다&amp;quot;라는 의미를 이름만으로도 충분히 유추가 가능하다. 따라서 한 클래스에 시그니처 생성자가 여러 개 필요하다면 생성자를 정적 팩토리 메서드로 바꾸고 그 특징을 설명할 수 있는 이름을 붙이자#### 2-2. 호출될 때마다 인스턴스를 새로 생성하지 않아도 된다.개인적으로는 큰 시스템일수록 가장 큰 장점이 되지 않을까 싶은데, 불변 클래스는 인스턴스를 미리 만들어 놓거나 새로 생성된 인스턴스를 캐싱하여 활용하기에 불필요한 객체 생성 방지한다. 위의 예제에서 본 Boolean.valueOf(boolean)을 보면 객체를 아얘 생성하지 않는다. 그래서 (특히 생성 비용이 큰) 같은 객체가 자주 요청되는 상황이라면 성능을 상당히 올려준다. 또한 이는 인스턴스의 생명 주기를 철저히 컨트롤 가능하는 뜻이며, 클래스를 싱글턴 혹은 인스턴스화 불가 상태로 만들 수도 있다.#### 2-3. 반환 타입의 하위 타입 객체를 반환할 수 있다.반환할 객체의 클래스를 자유롭게 선택할 수 있는 유연성을 제공한다. 응용하면 API를 만들 때 구현 클래스를 공개하지 않고 객체를 반환할 수 있어 API를 작게 유지가 가능하다. 자바 8 전에는 인터페이스에 정적 메서드 선언 불가하였고, 이름이 &amp;ldquo;Type&amp;quot;인 인터페이스를 반환하는 정적 메서드가 필요하면 &amp;ldquo;Types&amp;quot;라는 (인스턴스화 불가인) 동반 클래스를 만들어 그 안에 정의하는 것이 관례였다.예를 들어 자바 컬렉션 프레임워크는 핵심 인터페이스들에 수정 불가나 동기화 등의 기능을 붙인 총 45개의 유틸리티 구현체를 제공하고, 이 구현체 대부분을 단 하나의 인스턴스화 불가 클래스인 java.util.Collections에서 정적 팩토리 메서드를 통해 얻도록 한다.다음은 java.util.Collections의 동기화 기능의 정적 팩터리 메서드이다.![](/images/posts/53/스크린샷 2024-01-17 오후 5.31.56.png)![](/images/posts/53/스크린샷 2024-01-17 오후 5.30.15.png)컬렉션 프레임워크 자체는 이 45개 클래스를 공개하지 않기 때문에 API 외견을 훨씬 작게 만들 수 있었다. API가 작아진 것은 물론 개념적인 무게, 프로그래머가 API를 사용하기 위해 익혀야 하는 개념의 수와 난이도도 낮아졌다.(프로그래머는 명시한 인터페이스 대로 동작하는 객체를 얻을 것임을 알기에 굳이 문서를 찾거나 실제 구현클래스가 무엇인지 알아보지 않아도 된다. 나아가 정적 팩토리 메서드를 사용하는 클라이언트는 얻은 객체를 인터페이스만으로 다루게 된다.)추가로, 자바 8부터는 인터페이스가 정적 메서드를 가질 수 없다는 제한이 풀렸기에 인스턴스화 불가 동반 클래스를 둘 이유가 별로 없다. 동반 클래스에 두었던 public 정적 멤버들 상당수를 그냥 인터페이스 자체에 두면 된다. (자바 9에서는 private 정적 메서드까지 허용하지만 정적 필드와 정적 멤버 클래스는 여전히 public이어야만 함)#### 2-4. 입력 매개 변수에 따라 매번 다른 클래스의 객체를 반환할 수 있다.반환 타입의 하위타입이기만 하면 어떤 클래스의 객체를 반환하던 상관없다. 심지어 다음 릴리즈에서는 또 다른 클래스의 객체를 반환해도 된다. 즉 하위 타입이기만 하면 API 변경 시 또 다른 클래스의 객체를 반환해도 된다. 예를들어 EnumSet 클래스는 public 생성자 없이 정적 팩토리만 제공하는데 openjdk에서는 원소의 수에 따라 두 가지 하위 클래스중 하나의 인스턴스를 반환한다.![](/images/posts/53/스크린샷 2024-01-17 오후 5.39.08.png)반환 값을 보면 원소가 64개 이하면 long변수 하나로 원소를 관리하는 RegularEnumSet을, 65개 이상이면 long 배열로 관리하는 JumboEnumSet을 반환한다. 만약 원소가 적을 때 RegularEnumSet을 사용할 이점이 없어진다면 다음 릴리즈에는 이를 삭제해도 클라이언트는 아무런 변화도 알 수 없을 것이다.  클라이언트는 팩토리가 건네주는 객체가 어느 클래스의 인스턴스인지 알 수 없고 알 필요도 없다. EnumSet의 하위 클래스이기만 하면 된다.#### 2-5. 정적 팩토리 메서드를 작성하는 시점에는 반환할 객체의 클래스가 존재하지 않아도 된다.메서드를 작성하는 시점에 반환할 객체의 클래스가 존재하지 않는다는 것은 서비스 제공자 프레임워크 (service provider framework)의 근간이다. 이 뜻을 자세히 살펴보면서비스 제공자 프레임워크의 제공자(provider)는 서비스의 구현체이고, 이 구현체들을 클라이언트에 제공하는 역할을 프레임워크가 통제하여 클라이언트를 구현체로부터 분리해준다.서비스 제공자 프레임워크의 핵심 프레임워크 3가지는&amp;gt; 서비스 인터페이스 (service interface) - 구현체의 동작을 정의한다.제공자 등록 API(provider registration API) - 제공자가 구현체를 등록할 때 사용서비스 접근 API(service access API) - 클라이언트가 서비스의 인스턴스를 얻을 때 사용 (클라이언트는 서비스 접근 API를 사용할 때 원하는 구현체의 조건 명시 가능, 조건을 명시하지 않으면 기본 구현체를 반환하거나 지원하는 구현체들을 하나씩 돌아가며 반환)이 중 서비스 접근 API가 바로 앞서 말한 서비스 제공자 프레임워크의 근간이라고 한 유연한 정적팩토리의 실체이다. (추가로 서비스 인터페이스의 인스턴스를 생성하는 팩터리 객체를 설명하는 서비스 제공자 인터페이스 (Service Provider Interface)가 쓰이기도 한다.)익숙한 프레임워크이자 대표적인 서비스 제공자 프레임워크인 JDBC(java database connectivity)를 살펴보면 이해가 쉽다.&amp;gt; Connection - 서비스 인터페이스 역할DriverManager.registerDriver - 제공자 등록 API 역할DriverManager.getConnection - 서비스 접근 API 역할Driver - 서비스 제공자 인터페이스 역할(자바 6부터는 java.util.ServiceLoader라는 범용 서비스 제공자 프레임워크가 제공되어 프레임워크를 직접 만들 필요가 거의 없지만, JDBC는 6전에 등장하였기에 ServiceLoader를 사용하지 않는다.)## 3. 정적 팩토리 메서드 (static factory method)의 단점#### 3-1. 상속을 하려면 public, protected 생성자가 필요하니 정적 팩토리 메서드만 제공하면 하위 클래스 생성이 불가하다.컬렉션 프레임워크의 유틸리티 구현 클래스들은 상속이 불가하다는 말이다. 상속보다 컴포지션을 사용하도록 유도하고 불변타입으로 만들려면 이 제약을 지켜야 한다는 점에서 오히려 장점일 수도 있다.#### 3-2. 정적 팩토리 메서드는 프로그래머가 찾기 힘들다.생성자처럼 API 설명에 명확히 드러나지 않으니 사용자는 정적 팩터리 메서드 방식 클래스를 인스턴스화할 방법을 알아내야 한다. API 문서를 규격화하고, 메서드 명도 널리 알려진 규약에 따라 짓는 것으로 어느 정도 해결해야 한다.#### 3-3. 정적 팩토리 메서드에서 흔히 사용하는 네이밍- From : 매개변수를 하나 받아서 해당 타입 인스턴스를 반환하는 형변환 메서드 ex)&lt;code&gt;Date d = Date.from(instant);&lt;/code&gt;- Of : 여러 매개변수를 받아 적합한 타입의 인스턴스를 반환하는 집계 메서드&lt;code&gt;Set faceCards =EnumSet.of(JACK,QUEEN, KING);&lt;/code&gt;- valueOf : from과 of의 더 자세한 버전&lt;code&gt;BigInteger prime = BigInteger.valueOf(Integer.MAX_VALUE);&lt;/code&gt;- Instance / getInstance : (매개변수를 받는다면) 매개변수로 명시한 인스턴스를 반환하지만, 같은 인스턴스임을 보장하지는 않음&lt;code&gt;StackWalker Luke = StackWalker.getInstance(options);&lt;/code&gt;- Create/newInstance : instance/getInstance와 같지만, 매번 새로운 인스턴스를 생성해 반환함을 보장 ex)&lt;code&gt;Object newArray = Array.newInstance(classObject, arrayLen);&lt;/code&gt;- getType : getInstance와 같으나, 생성할 클래스가 아닌 다른 클래스에 팩토리 매서드를 정의할 때 사용. &amp;ldquo;Type&amp;quot;은 팩터리 메서드가 반환할 객체의 타입&lt;code&gt;FileStore fs = Files.getFileStore(path)&lt;/code&gt;- newType : newInstance와 같으나, 생성할 클래스가 아닌 다른 클래스에 팩터리 메서드를 정의할 때 사용. &amp;ldquo;Type&amp;quot;은 팩터리 메서드가 반환할 객체의 타입&lt;code&gt;BufferReader br = Files.newFufferedReader(path)&lt;/code&gt;- type : getType과 newType의 간결한 버전&lt;code&gt;List litany = Collections.list(legacyLitany);&lt;/code&gt;## 4. 정리적정 팩터리 매서드와 public 생성자는 각각 쓰임새가 있으니 장담점을 이해하고 써야 한다. 정적 팩토리를 사용할 경우가 유리한 경우가 더 많기에 무작정 public 생성자를 썼다면 다시 한번 생각해 보자책의 예제 소스와 상세 내용은 다음 repo에서 확인 가능하다.&lt;a href=&#34;https://github.com/junhkang/effective-java-summary&#34;&gt;https://github.com/junhkang/effective-java-summary&lt;/a&gt;GitHub - junhkang/effective-java-summary: A personal summary of Effective Java (by Joshua Bloch)A personal summary of Effective Java (by Joshua Bloch) - GitHub - junhkang/effective-java-summary: A personal summary of Effective Java (by Joshua Bloch)github.com#Effective Java #정적 팩토리 메서드&lt;/p&gt;</description>
    </item>
    <item>
      <title>[이펙티브 자바] 6. 불필요한 객체 생성을 피하라</title>
      <link>http://localhost:1313/posts/77/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/77/</guid>
      <description>&lt;p&gt;똑같은 객체를 매번 새로 생성하는 것보다 하나를 생성 후 재사용하는 것이 훨씬 효율적이다. 특히 불변 객체는 언제든 재사용이 가능하다. 다음은 객체 생성 시 사용하면 안 되는 극단적인 예이다.&lt;code&gt;String s = new String(&amp;quot;bikini&amp;quot;);&lt;/code&gt;보기만 해도 불편한 이 생성방식은 실행될 때마다 String 객체를 새로 생성한다. 이후에 기능적으로는 동일하게 사용되지만 큰 반복문이나 자주 호출되는 메서드 안에 있다면 쓸모없는 인스턴스가 여러 개 생성될 것이다. 개선된 객체 생성 방식을 확인해 보자.&lt;code&gt;String s = &amp;quot;bikini&amp;quot;;&lt;/code&gt;이제 익숙한 String 객체 선언 방식이 되었다. 새로운 인스턴스를 매번 만드는 대신 하나의 String 인스턴스 사용하는 방식으로, 이 방식을 사용하면 같은 가상 머신 안에서 이와 같은 문자열 리터럴을 사용하는 모든 코드가 같은 객체를 재사용함이 보장된다. 생성자 대신 정적 팩토리를 제공하는 불변 클래스에서도 정적 팩터리 메서드를 사용해서 불필요한 객체 생성을 피할 수 있다. 예를들어 Boolean 생성자 대신 Boolean.valueOf 팩토리 메서드를 사용하면 호출될 때마다 새로운 객체가 생성되는 것을 방지할 수 있다.## 2. 객체의 반복 시 캐싱 사용불변객체뿐 아니라 가변객체도 사용 중에 변경되지 않는다는 것을 알 수 있다면 재사용이 가능하다. 특히 생성 비용이 비싼 객체의 생성이 반복해서 필요할 경우 캐싱하여 사용 권장한다. 주어진 문자열이 유효한 로마 숫자인지를 확인하는 메서드 예제를 확인해 보자.&lt;code&gt;static boolean isRomanNumeral(String s) {return s.matches(&amp;quot;^(&amp;gt;=.)M*(C[MD]|D?C{0,3})&amp;quot;+ &amp;quot;(X[CL]|L?X{0,3})(I[XV]|V?I{0,3})$&amp;quot;);}&lt;/code&gt;기능상으로는 문제가 없는 String.matches를 사용한 정규표현식으로 문자열 형태를 확인하는 가장 쉬운 방법 중 하나이다. 하지만 빈번한 호출이 있을 경우 성능 측면에서는 적합하지 않다. Pattern 인스턴스는 한번 사용하고 버려 저서 바로 GC대상이 되며 Pattern은 입력받은 정규표현식에 해당하는 유한 상태머신을 만들기 때문에 인스턴스 생성비용이 높다&amp;gt; 유한 상태머신 [Finite State Machine (FS)] - 단순히 객체를 생성하는 것이 아니라 정규표현식에 일치하는 문자열을 찾기 위해 문자열을 상태에 따라 순차적으로 처리하는 논리 구조를 생성하기에 계산적으로 복잡하고 리소스를 많이 사용한다.성능을 개선하려면 Pattern 인스턴스를 클래스 초기화 과정에서 생성하여 캐싱하고 isRomanNumeral이 호출될 때마다 재사용하는 방법을 적용하면 된다.&lt;code&gt;public class RomanNumerals {private static final Pattern ROMAN = Pattern.compile(&amp;quot;^(&amp;gt;=.)M*(C[MD]|D?C{0,3})&amp;quot;+ &amp;quot;(X[CL]|L?X{0,3})(I[XV]|V?I{0,3})$&amp;quot;);static boolean isRomanNumeral(String s) {return ROMAN.matcher(s).matches();}}&lt;/code&gt;isRomanNumeral이 자주 호출될 때 성능개선 효과를 볼 수 있으며 ROMAN 필드를 final로 꺼내면서 의미가 더 명확해진다.8글자 기준으로 100,000번 반복 호출 시 거의 10배의 시간 효율을 확인할 수 있었다. (테스트 코드는 깃허브에서 확인 가능)![](/images/posts/77/스크린샷 2024-03-26 오후 5.23.04.png)반면 isRomanNumeral 방식의 클래스가 초기화된 후 이 메서드를 한 번도 호출하지 않으면 ROMAN필드는 쓸데없이 초기화된 것이다.이 경우 isRomanNumeral 메서드가 처음 호출될 때 필드를 초기화하는 지연 초기화로 불필요한 초기화를 없앨 순 있지만 성능개선에 비해 코드복잡도가 올라가서 추천하지 않은 방식이다.## 3. 불필요한 객체 생성 (keySet)객체가 불변이면 재사용하는 것이 항상 안전하지만, 불변인지 명확하지 않은 경우도 있다.Map 인터페이스의 keySet 메서드를 확인해 보자. Map인터페이스의 KeySet메서드는 Map 객체 안의 키를 Set뷰로 반환한다.  뷰를 통해 원본 &amp;lsquo;Map&amp;rsquo;에서 키를 제거하는 등, 반환된 Set인스턴스가 가변이더라도 모든 반환된 &amp;lsquo;Set&amp;rsquo; 인스턴스는 동일한 &amp;lsquo;Map&amp;rsquo; 인스턴스를 대변하기 때문에 기능적으로 정확히 일치한다. 반환된 &amp;lsquo;Set&amp;rsquo;을 통해 원본 &amp;lsquo;Map&amp;rsquo;의 키를 수정하거나 제거하면, 이변경 사항이 &amp;lsquo;Map&amp;rsquo;에 그대로 반영되어 참조하는 모든 뷰에 영향을 미치기에 반환한 객체 중 하나를 수정하면 다른 모든 객체가 따라서 바뀌게 된다.따라서 &amp;lsquo;keySet&amp;rsquo; 메서드를 여러 번 호출하여 여러 개의 &amp;lsquo;Set&amp;rsquo; 뷰를 생성해도 기능상 문제는 없지만, 실질적으로 볼 수 있는 효과가 없다. 모든 &amp;lsquo;Set&amp;rsquo; 뷰는 원본 &amp;lsquo;Map&amp;rsquo;을 참조하기에 여러뷰를 생성하는 것보다 단일 뷰를 재사용하는 것이 효율적이다.## 4. 오토박싱불필요한 객체를 만들어내는 또 다른 방식으로는 오토박싱이 있다. 자바에서 기본 타입과 박싱 된 기본타입을 섞어 쓸 때 자동으로 상호변환해 주는 기능이다. 다만 오토박싱은 기본 타입과 박싱 된 타입의 구분을 흐리게 해 주지만 아얘 구분을 없애는 것은 아니다.다음 예제는 모든 양의 정수의 총합을 구하는 메서드로 int는 충분히 크지 않아 long을 사용 중이다. 기능 상으로는 동일하지만 성능에서는 오토박싱을 사용함으로써 성능에서 큰 차이를 보이고 있다.### 3-1. 오토박싱 사용&lt;code&gt;private static long sumLong()   {Long sum = 0L;for (long i = 0; i &amp;lt;= Integer.MAX_VALUE; i++) {sum += i;}return sum;}&lt;/code&gt;### 3-2. 기본 타입사용&lt;code&gt;private static long sumlong()   {Long sum = 0L;for (long i = 0; i &amp;lt;= Integer.MAX_VALUE; i++) {sum += i;}return sum;}&lt;/code&gt;오토박싱을 사용한 예제를 보면 sum 변수를 Long으로 선언하여 불필요한 Long인스턴스가 2^31개나 생성된다. 실제로 두 메서드의 실행 시간을 비교해 보면 아주 큰 차이가 남을 확인할 수 있다.![](/images/posts/77/스크린샷 2024-03-26 오후 5.34.15.png)그래서 박싱 된 기본 타입보다는 기본 타입을 사용하고, 의도치 않은 오토박싱이 숨어들지 않도록 주의해야 한다.## 4. 주의객체의 재사용이 효율적임을 강조했지만, 이펙티브 자바에서는 무조건적인 재사용이 효율적이지 않은 상황도 공유하고 있다. 프로그램의 명확성, 간결성, 기능을 위한 객체 생성은 일반적으로 좋지만 단순히 재사용성을 높이기 위해 객체 pool을 생성하는 것은 효율적이지 못하다. 데이터베이스 연결 같은 경우 생성 비용이 워낙 비싸기에 객체 pool(집합)을 생성하여 재사용하는 것이 효율적이지만,  일반적으로 자체 객체 풀은 객체를 풀에서 반환하는 추가로직이 필요하기에 코드의 명확성과 간결성이 떨어진다. 또한 사용하지 않는 개체들이 메모리에 남아있게 되어 메모리 사용량이 증가하게 된다. 또한 JVM GC가 상당히 최적화되어 있어 가벼운 객체를 효율적으로 관리하고 메모리를 회수하는데 최적화되어있기에, 가벼운 객체의 경우는 직접풀을 관리하는 것보다 새로 생성하는 것이 효율적일 수 있다.## 5. 정리- 불변이 보장된 객체의 경우 재사용을 항상 고려- 무거운 객체의 반복 생성 시 캐싱을 사용- 불필요한 객체 생성을 주의- 의도치 않은 오토박싱이 숨어들지 않도록 주의- 데이터베이스 연결 같이 생성 비용이 아주 큰 경우를 제외하고는 객체 풀을 사용하여 객체를 재사용하는 것보다 새로 생성하는 것이 효율적예제 및 성능 테스트 코드&lt;a href=&#34;https://github.com/junhkang/effective-java-summary/tree/master/src/main/java/org/example/ch01/item06/codes&#34;&gt;https://github.com/junhkang/effective-java-summary/tree/master/src/main/java/org/example/ch01/item06/codes&lt;/a&gt;#이펙티브자바&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
